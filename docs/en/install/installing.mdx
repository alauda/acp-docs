---
weight: 30
i18n:
  title:
    en: Installing
---

# Installing

This section provides the specific steps for installing the management cluster. Before starting the installation, ensure that prerequisite checks, installation package download and verification, and node preprocessing are completed.

<Steps>
### Upload and Extract the Installation Package

Upload the installation package to any machine on the management cluster control node and extract it using the following command:

```shell
# Assuming the machine already has the /root/cpaas-install folder
tar -xvf {installation_package_path}/{installation_package_filename} -C /root/cpaas-install
cd /root/cpaas-install/installer || exit 1
```

<Directive type="info" title="INFO">
- This machine will become the first control node after the management cluster installation is completed.
- The installation package extraction requires at least **100GB** of disk space. Please ensure sufficient storage resources.
</Directive>

### Start the Installer

Execute the following installation script to start the management cluster installer. Once the installer starts successfully, the command line terminal will output the UI access address. After about 5 minutes, you can access the installerâ€™s Web UI on a PC browser.

```bash
bash setup.sh
```

By default, the installer uses the Kube-OVN network plugin. To use the Calico network plugin, execute:

```bash
bash setup.sh --network-mode calico
```

<Directive type="note" title="Other Parameters">
- To use IPv6 addresses: add the `--ip-family ipv6` parameter.
- To support both IPv4 and IPv6: add the `--ip-family dual` parameter.
</Directive>

### Parameter Configuration

Follow the on-screen prompts to complete the installation parameter configuration and confirm the installation. Detailed explanations for the key parameters can be found in [Parameter Explanation](#parameters). Please read carefully and configure according to your actual requirements.

### Verify Installation Success

After installation, the page will display the platform access address. Click the **Access** button to go to the platform Web UI.

In the **Platform Management** view, click **Cluster Management > Clusters**, and find the cluster named `global`.

From the right drop-down menu, select `CLI Tools`, and execute the following command to verify the installation status:

```shell
# Check for any failed charts
kubectl get apprelease --all-namespaces
# Check for any failed pods
kubectl get pod --all-namespaces | awk '{if ($4 != "Running" && $4 != "Completed")print}' | awk -F'[/ ]+' '{if ($3 != $4)print}'
```
</Steps>

## Parameter Explanation \{#parameters}
<table>
  <tr>
    <th style={{ whiteSpace: 'nowrap' }}>Parameter</th>
    <th style={{ whiteSpace: 'nowrap' }}>Explanation</th>
  </tr>
  <tr>
    <td><b>Kubernetes Version</b></td>
    <td>
      Available versions have been rigorously tested to ensure stability and compatibility.<br />
      <b>Recommendation:</b> Select the latest version to get the best functionality and support.
    </td>
  </tr>
  <tr>
    <td><b>Cluster Network Protocol</b></td>
    <td>
      Supports three modes: IPv4-only, IPv6-only, IPv4/IPv6 dual-stack.<br />
      <b>Note:</b> If you choose the dual-stack mode, ensure that all nodes are correctly configured with IPv6 addresses; once the network protocol is set, it cannot be changed later.
    </td>
  </tr>
  <tr>
    <td><b>Cluster Address</b></td>
    <td>
      Enter the pre-prepared <code>global VIP</code>, which will be used as the access address for the <code>kube-apiserver</code> service outside the cluster.<br />
      If a LoadBalancer has been configured during the preparation of [Network Resources](./prepare/prerequisites.mdx#network-resources), provide its VIP address and disable the <code>Self-Managed VIP</code> option.<br />
      If no LoadBalancer is configured, enable <code>Self-Managed VIP</code> and enter the requested VIP address. The installer will automatically deploy <code>keepalived</code> to provide software load balancing support.<br />
      <b>Note:</b> Using <code>Self-Managed VIP</code> requires the following conditions:<br />
      - A usable VRID is available;<br />
      - Host network supports VRRP protocol;<br />
      - All control nodes and the VIP must be in the same subnet.
    </td>
  </tr>
  <tr>
    <td><b>Platform Access Address</b></td>
    <td>
      Enter the pre-prepared <code>External IP</code> or <code>domain name</code>.<br />
      By default, the platform uses HTTPS for access; if HTTP is required, enable it in <b>Advanced Settings</b> (not recommended).<br />
      If multiple access addresses are needed (e.g., different internal and external addresses), enter the internal address and add the external address in <b>Advanced Settings &gt; Other Settings &gt; Additional Platform Access Addresses</b>.<br />
      If additional access addresses are required after installation, refer to the user manual for instructions on how to modify this via the Web UI.
    </td>
  </tr>
  <tr>
    <td><b>Certificate</b></td>
    <td>
      The platform provides a self-signed certificate for HTTPS access by default.<br />
      If you wish to use a custom certificate, you can upload your existing certificate.
    </td>
  </tr>
  <tr>
    <td><b>Image Repository</b></td>
    <td>
      The platform uses the <code>Platform-Deploy</code> image repository by default, which includes all component images.<br />
      If you wish to use an <code>External</code> image repository, please contact technical support for the image synchronization plan before configuring it.
    </td>
  </tr>
  <tr>
    <td><b>Container Network</b></td>
    <td>
      The default subnet and Service network segment of the management cluster must not overlap.<br />
      When using the Kube-OVN Overlay network, ensure that the container network and the host network are not on the same subnet to prevent network issues.
    </td>
  </tr>
  <tr>
    <td><b>Node Name</b></td>
    <td>
      If <code>Host Name as Node Name</code> is chosen, ensure all node host names are unique.
    </td>
  </tr>
  <tr>
    <td><b>global Cluster Platform Node Isolation</b></td>
    <td>
      Only enable this when you plan to run business workloads within the management cluster.<br />
      <b>After enabling:</b><br />
      - Nodes can be set to <code>Platform Exclusive</code>, meaning they will only run platform components, ensuring isolation between platform and business workloads;<br />
      - DaemonSet-type workloads are exceptions.
    </td>
  </tr>
  <tr>
    <td><b>Add Node</b></td>
    <td>
      <b>Control Node:</b>
      <ul>
        <li>Support adding 1 or 3 control nodes (3 for high availability configuration);</li>
        <li>If <code>Platform Exclusive</code> is enabled, <code>Deployable Applications</code> will be disabled, and control nodes will only run platform components;</li>
        <li>If <code>Platform Exclusive</code> is disabled, you can choose whether to enable <code>Deployable Applications</code>, allowing the control node to run business workloads.</li>
      </ul>

      <b>Compute Node:</b>
      <ul>
        <li>If <code>Platform Exclusive</code> is enabled, <code>Deployable Applications</code> will be disabled;</li>
        <li>If <code>Platform Exclusive</code> is disabled, <code>Deployable Applications</code> will be enabled.</li>
      </ul>

      <p>When using Kube-OVN, you can specify the node's network interface by entering the gateway name.</p>
      <p>If the node availability check fails, please adjust according to the page prompt and re-add the node.</p>
    </td>
  </tr>
</table>

---
