---
weight: 10
---

# Prerequisites

Before installing the `global` cluster, you need to prepare hardware, network, and OS that meet the requirements.

:::info
1. The platform currently does not support direct installation of the `global` cluster in an existing Kubernetes environment. If your environment already has a Kubernetes cluster, please back up your data and clean the environment before installation.
2. If you plan to use global Cluster Disaster Recovery, please first read [global Cluster Disaster Recovery](../global_dr.mdx).
:::

## **Resource Planning**

This section provides guidelines for resource planning before installing <Term name="productShort" />.
Choose the appropriate deployment scenario based on your environment and usage needs, and prepare resources accordingly.

:::info
The following recommendations only cover the minimum resources required for a successful installation of the **Global cluster**.

They **do not** include the resources required for any **additional extensions or components** deployed on the Global cluster.

For detailed requirements of each extension, refer to the corresponding component documentation.
:::

### **Deployment Architectures**

Before installation, you must determine which deployment architecture best fits your use case.
<Term name="productShort" /> supports the following three common deployment architectures:

* **Multi-Cluster**

  Select this architecture if you need to centrally manage multiple Kubernetes clusters.
  In this mode, <Term name="productShort" /> consists of one **Global cluster** and multiple **workload clusters**.
  Running non-platform workloads on the Global cluster may degrade platform stability and performance, and should be avoided.

* **Single Cluster**

  Select this architecture if you plan to install only one cluster and run workloads directly on it.
  In this mode, the Global cluster also acts as a workload cluster, and therefore requires **more resources** compared with a pure Global-only setup in Multi-Cluster mode.

* **Single Node**

  :::warning
  This architecture is intended solely for testing or proof-of-concept purposes and should not be used in production.
  :::

### **Single Node**

The following table lists the **minimum hardware requirements** for installing <Term name="productShort" /> in **Single Node** mode.

| Resource | Minimum Requirement | Description |
| -------- | ------------------- | ----------- |
| CPU      |                     |             |
| Memory   |                     |             |
| Storage  |                     |             |

### **Single Cluster**

In this mode, the Global cluster serves both as the control plane and as the workload cluster.
The total resource requirement consists of two parts:

* **Base resources** for the Global cluster itself
* **Additional resources** for running workloads on the same cluster

The minimum resources required for a **highly available Global cluster** are as follows:

| Resource | Minimum Requirement | Description |
| -------- | ------------------- | ----------- |
| CPU      |                     |             |
| Memory   |                     |             |
| Storage  |                     |             |

To estimate the additional resources required for your workloads, refer to
[**Evaluating Resources for Workload Cluster**](../../configure/scalability/evaluating_workload.mdx)

### **Multi-Cluster**

When managing multiple workload clusters, the resource usage of the Global cluster increases proportionally with the number of managed clusters.
The additional overhead mainly comes from cluster registration, monitoring, and control-plane synchronization.

To estimate the resources required for your Global cluster based on the number of managed clusters, refer to [**Evaluating Resources for Global Cluster**](../../configure/scalability/evaluating_global.mdx)

:::warning
For ARM architectures (such as Kunpeng 920), it is recommended to increase the configuration to **2 times** that of the x86 minimum configuration, but not less than **1.5 times**.

For example: If x86 requires 8 cores 16GB, then ARM should reach at least 12 cores 24GB, and the recommended configuration is 16 cores 32GB.
:::

## Supported OS and Kernels \{#supported_os_and_kernels}

:::info
1. **Kernel Version Requirements:**
   These kernel versions have been officially released and validated by our platform tests. In your actual deployment, adherence to the **A.B.C major version numbers** is crucial, while subsequent minor versions can vary.
2. **Unsupported Environments:**
   If the OS, kernel version, or CPU architecture does not meet the requirements, please contact technical support.
:::

### x86

<Tabs>
  <Tab label="Red Hat Enterprise Linux (RHEL)">
  - RHEL 7.8: `3.10.0-1127.el7.x86_64`
  - RHEL 8.0 to 8.6: `4.18.0-80.el8.x86_64` to `4.18.0-372.9.1.el8.x86_64`
  <Directive type="warning" title="WARNING">
  RHEL 7.8 does not support **Calico Vxlan IPv6**.
  </Directive>
  </Tab>

  <Tab label="CentOS">
  - CentOS 7.6 to 7.9: `3.10.0-1127` to `3.11`
  <Directive type="warning" title="WARNING">
  CentOS does not support **Calico Vxlan IPv6**.
  </Directive>
  </Tab>

  <Tab label="Ubuntu">
  - Ubuntu 20.04 LTS: `5.4.0-124-generic`
  - Ubuntu 22.04 LTS: `5.15.0-56-generic`
  <Directive type="warning" title="WARNING">
  Ubuntu HWE (Hardware Enablement) versions are not supported.
  </Directive>
  </Tab>

  <Tab label="Kylin Linux Advanced Server">
  - Kylin V10 SP3: `4.19.90-52.22.v2207.ky10.x86_64`
  <Directive type="warning" title="WARNING">
  - Kylin V10, V10-SP1, and V10-SP2 have known kernel issues that may cause **NodePort network access failures**; it is recommended to upgrade to **Kylin V10-SP3**.
  </Directive>
  </Tab>
</Tabs>

### ARM

<Tabs>
  <Tab label="Kylin Linux Advanced Server">
  - Kylin V10 SP3: `4.19.90-52.22.v2207.ky10.x86_64`
  <Directive type="warning" title="WARNING">
  - Kylin V10, V10-SP1, and V10-SP2 have known kernel issues that may cause **NodePort network access failures**; it is recommended to upgrade to **Kylin V10-SP3**.
  - ARM architecture only supports `Kunpeng 920`. For other models, please contact technical support.
  </Directive>
  </Tab>
</Tabs>

## Network

Before installation, the following network resources must be pre-configured. If a hardware LoadBalancer cannot be provided, the installer supports configuring **haproxy + keepalived** as a software load balancer, but you need to understand:

- **Poorer Performance**: Software load balancing performance is lower than hardware LoadBalancer.
- **Higher Complexity**: If you are not familiar with keepalived, it may cause the `global` cluster to be unavailable, problem troubleshooting will take a long time, and seriously affect platform reliability.

### Network Resources \{#network-resources}

<table>
  <thead>
    <tr>
      <th style={{ whiteSpace: 'nowrap' }}>Resource</th>
      <th style={{ whiteSpace: 'nowrap' }}>Mandatory</th>
      <th style={{ whiteSpace: 'nowrap' }}>Quantity</th>
      <th style={{ whiteSpace: 'nowrap' }}>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style={{ whiteSpace: 'nowrap' }}>`global` VIP</td>
      <td>Mandatory</td>
      <td>1</td>
      <td>Used for nodes in the cluster to access kube-apiserver, configured in the load balancing device to ensure high availability. <br />This IP can also be used as the access address for the platform Web UI. <br />Workload clusters in the same network as the `global` cluster can also access the `global` cluster through this IP.</td>
    </tr>
    <tr>
      <td style={{ whiteSpace: 'nowrap' }}>External IP</td>
      <td>Optional</td>
      <td>On Demand</td>
      <td>When there are workload clusters that are not in the same network as the `global` cluster, such as a hybrid cloud scenario, it must be provided. Workload clusters in other networks access the `global` cluster through this IP. <br />This IP needs to be configured in the load balancing device to ensure high availability. <br />This IP can also be used as the access address for the platform Web UI.</td>
    </tr>
    <tr>
      <td>Domain Name</td>
      <td>Optional</td>
      <td>On Demand</td>
      <td>If you need to access the `global` cluster or platform Web UI through a domain name, please provide it in advance and ensure that the domain name resolution is correct.</td>
    </tr>
    <tr>
      <td>Certificate</td>
      <td>Optional</td>
      <td>On Demand</td>
      <td>It is recommended to use a trusted certificate to avoid browser security warnings; if not provided, the installer will generate a self-signed certificate, but there may be security risks when using HTTPS.</td>
    </tr>
  </tbody>
</table>

<Directive type="info" title="INFO">
A domain name must be provided in the following cases:
1. The `global` cluster needs to support IPv6 access.
2. A disaster recovery plan for the `global` cluster is planned.
</Directive>

<Directive type="note" title="NOTE">
If the platform needs to configure multiple access addresses (for example, addresses for internal and external networks), please prepare the corresponding IP addresses or domain names in advance according to the table above. You can configure them in the installation parameters later, or add them according to the product documentation after installation.
</Directive>

### Network Configuration

<table>
  <thead>
    <tr>
      <th style={{ whiteSpace: 'nowrap' }}>Type</th>
      <th style={{ whiteSpace: 'nowrap' }}>Requirement Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style={{ whiteSpace: 'nowrap' }}>Network Speed</td>
      <td>Speed of `global` cluster and workload cluster in the same network ≥1Gbps (recommended 10Gbps); cross-network speed ≥100Mbps (recommended 1Gbps). <br />Insufficient speed will significantly reduce data query performance.</td>
    </tr>
    <tr>
      <td style={{ whiteSpace: 'nowrap' }}>Network Latency</td>
      <td>Latency ≤2ms in the same network; latency ≤100ms (recommended ≤30ms) across networks.</td>
    </tr>
    <tr>
      <td style={{ whiteSpace: 'nowrap' }}>Network Policy</td>
      <td>Please refer to [LoadBalancer Forwarding Rules](#port-forward) to ensure that the necessary ports are open; when using Calico CNI, ensure that the **IP-in-IP** protocol is enabled.</td>
    </tr>
    <tr>
      <td style={{ whiteSpace: 'nowrap' }}>IP Address Range</td>
      <td>The `global` cluster nodes should avoid using the 172.16-32 network segment. If it has been used, please adjust the Docker configuration (add the bip parameter) to avoid conflicts.</td>
    </tr>
  </tbody>
</table>

### LoadBalancer Forwarding Rules \{#port-forward}

This rule is designed to ensure that the `global` cluster can receive traffic from the LoadBalancer normally. Please check the network policy according to the following table to ensure that the relevant ports are open.

<table>
  <thead>
    <tr>
      <th style={{ whiteSpace: 'nowrap' }}>Source IP</th>
      <th style={{ whiteSpace: 'nowrap' }}>Protocol</th>
      <th style={{ whiteSpace: 'nowrap' }}>Destination IP</th>
      <th style={{ whiteSpace: 'nowrap' }}>Destination Port</th>
      <th style={{ whiteSpace: 'nowrap' }}>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>`global` VIP, External IP</td>
      <td style={{ whiteSpace: 'nowrap' }}>TCP</td>
      <td>All control plane node IPs</td>
      <td style={{ whiteSpace: 'nowrap' }}>443</td>
      <td>
        Provides access services for the platform Web UI, image repository, and Kubernetes API Server through the HTTPS protocol. The default port is `443`. If you need to use a custom HTTPS port, please do the following:<br />
        - Replace the destination port in the port forwarding rule with your custom port number.<br />
        - Later, in the Web UI installation parameters, fill in your custom port number.
      </td>
    </tr>
    <tr>
      <td>`global` VIP, External IP</td>
      <td style={{ whiteSpace: 'nowrap' }}>TCP</td>
      <td>All control plane node IPs</td>
      <td style={{ whiteSpace: 'nowrap' }}>6443</td>
      <td>
        This port provides access to the Kubernetes API Server for nodes within the cluster.
      </td>
    </tr>
    <tr>
      <td>`global` VIP, External IP</td>
      <td style={{ whiteSpace: 'nowrap' }}>TCP</td>
      <td>All control plane node IPs</td>
      <td style={{ whiteSpace: 'nowrap' }}>11443</td>
      <td>
        This port provides access to the image repository for nodes within the cluster.<br />
        <b>Note:</b> If you plan to use an external image repository instead of the default image repository provided by the `global` cluster, you do not need to configure this port.
      </td>
    </tr>
  </tbody>
</table>

<Directive type="tip" title="TIP">
- It is recommended to configure health checks on the LoadBalancer to monitor the port status.
- If you plan to implement a disaster recovery plan for the `global` cluster, you need to open port `2379` for all control plane nodes for ETCD data synchronization between the primary and disaster recovery clusters.
- The platform only supports HTTPS by default. If HTTP support is required, you need to open the HTTP port for all control plane nodes.
</Directive>
