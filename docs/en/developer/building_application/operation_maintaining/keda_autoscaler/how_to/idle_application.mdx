---
weight: 63
i18n:
  title:
    en: Traffic-Based Idle Application Solution
    zh: 基于流量的闲置应用解决方案
---

# Traffic-Based Idle Application Solution

## Overview
The Traffic-Based Idle Application Solution is an innovative cloud-native technology that automatically adjusts resource allocation based on application HTTP traffic. This solution, built on the KEDA HTTP Add-on project, delivers the following core capabilities:

### Introduction
Core Features:
- **Automatic Scale from Zero**: Automatically starts applications from zero replicas when HTTP requests arrive.
- **Intelligent Scale to Zero**: Automatically scales applications to zero replicas during no-traffic periods, saving resource costs.
- **Zero Request Loss**: Ensures no requests are lost during application startup through intelligent buffering mechanism.
- **Fast Cold Start**: Optimized startup process ensures quick response to traffic spikes.

Applicable Scenarios:
- Web services with fluctuating traffic
- Internal tools and dashboard applications.
- API frontends for batch processing jobs
- Development and test environment resource optimization.

### Core Architecture Components
The below diagram is the most common architecture that is shipped by default:
![KEDA Http Add-on Architecture](../../assets/keda-http-add-on-arch.png)

Component Responsibilities:
1. **Interceptor**: 
  - Receives and proxies all incoming HTTP traffic
  - Buffers requests during application startup
  - Routes requests to correct backend services based on Host header
  - Collects request queue metrics
2. **HTTP Scaler**:
  - Exposes HTTP-related metrics to KEDA
  - Triggers scaling events based on configured thresholds
  - Monitors application readiness status
3. **HTTP Operator**:
  - Manages `HTTPScaledObject` custom resources
  - Synchronizes configurations across components
  - Maintains system health status
4. **KEDA Core**:
  - Drives `HPA` based on external metrics
  - Supports multiple event sources and metric sources
  - Provides unified auto-scaling engine

## Installation and Practice

### Install KEDA
Follow the [Installing KEDA](../install_keda_operator.mdx) to install KEDA in your workload cluster.

### Install HTTP Add-on
Follow the [Installing the KEDA HTTP Add-on](https://github.com/kedacore/http-add-on/blob/main/docs/install.md) to install HTTP Add-on in your workload cluster.

### Application Demo
Create Sample Application:
```bash
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sample-app
spec:
  replicas: 0  # Start with zero replicas
  selector:
    matchLabels:
      app: sample-app
  template:
    metadata:
      labels:
        app: sample-app
    spec:
      containers:
      - name: app
        image: nginx:latest
        ports:
        - containerPort: 80
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: sample-app
spec:
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: sample-app
EOF
```
Configure Auto-scaling:
```bash
kubectl apply -f - <<EOF
apiVersion: http.keda.sh/v1alpha1
kind: HTTPScaledObject
metadata:
  name: sample-app-scaler
spec:
  scaleTargetRef:
    deployment: sample-app
    service: sample-app
    port: 80
  replicas:
    min: 0
    max: 5
  targetPendingRequests: 10
EOF
```

## Scale from Zero

### Practice Steps
1. Verify Initial State:
   ```bash
   kubectl get deployment sample-app
   ```
2. Get Access Address:
   ```bash
   kubectl get service -n keda -l app.kubernetes.io/name=keda-add-ons-http-interceptor-proxy
   ```
3. Send Test Requests to Trigger Scaling:
   ```bash
   # Send HTTP request to trigger scaling
   curl -H "Host: sample-app.default.svc.cluster.local" http://<service-ip>/

   # Or use load testing tool
   hey -n 100 -c 10 -H "Host: sample-app.default.svc.cluster.local" http://<service-ip>/
   ```
4. Monitor Scaling Process:
   ```bash
   # Real-time monitoring of Pod creation
   kubectl get pods -l app=sample-app -w

   # Check HPA status
   kubectl get hpa -w

   # View detailed logs
   kubectl logs -f -n keda deployment/keda-http-operator
   ```

### Scale from Zero Process
![KEDA Http Add-on Scale from Zero](../../assets/keda-http-add-on-scale-from-zero.svg)

## Scale to Zero

### Practice Steps

1. Observe Running State:
   ```bash
   # Confirm application is running
   kubectl get deployment sample-app
   # Output should show READY 1/1 or more

   kubectl get pods -l app=sample-app
   # View running Pods
   ```
2. Stop Traffic Generation:
   ```bash
   # Stop all load testing tools
   # Wait for system to detect no-traffic state
   ```
3. Monitor Scale-down Process:
   ```bash
   # Watch HPA status
   kubectl get hpa -w

   # Check if replicas are scaling down to zero
   kubectl get deployment sample-app -w
   # Output should show 0/0 replicas
   ```
4. Verify Scale-down Result:
   ```bash
   # After waiting, confirm scale-down complete
   kubectl get deployment sample-app
   # Output should show READY 0/0

   kubectl get pods -l app=sample-app
   # Should show No resources found
   ```

### Scale to Zero Process
![KEDA Http Add-on Scale to Zero](../../assets/keda-http-add-on-scale-to-zero.svg)

Configuration Optimization Suggestions:
```yaml
# Optimized HTTPScaledObject configuration
apiVersion: http.keda.sh/v1alpha1
kind: HTTPScaledObject
metadata:
  name: optimized-scaler
spec:
  scaleTargetRef:
    deployment: sample-app
    service: sample-app
    port: 80
  replicas:
    min: 0
    max: 5
  targetPendingRequests: 5      # More sensitive scale-up threshold
  scaledownPeriod: 180          # Shorter scale-down wait time (seconds)
  timeout: 30                   # Request timeout
```

## Conclusion

The traffic-driven idle application solution based on KEDA HTTP Add-on brings significant value to modern cloud-native environments:
1. Ultimate Cost Optimization: Maximize cost efficiency by scaling idle applications to zero.
2. Intelligent Elastic Scaling: Automatically adjust based on actual traffic, no manual intervention required
3. High Availability Assurance: Zero request loss ensured through request buffering mechanism
4. Simple and Easy to Use: Standard Kubernetes-native experience with low learning curve
