---
weight: 10
i18n:
  title:
    en: Deployments
    zh: 部署
---

# Deployments

## Understanding Deployments
Refer to the official Kubernetes documentation: [Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)

> **Deployment** is a Kubernetes higher-level workload resource used to declaratively manage and update Pod replicas for your applications. It provides a robust and flexible way to define how your application should run, including how many replicas to maintain and how to safely perform rolling updates.

A **Deployment** is an object in the Kubernetes API that manages Pods and ReplicaSets. When you create a Deployment, Kubernetes automatically creates a ReplicaSet, which is then responsible for maintaining the specified number of Pod replicas.

**By using Deployments, you can**:

- Declarative Management: Define the desired state of your application, and Kubernetes automatically ensures the cluster's actual state matches the desired state.
- Version Control and Rollback: Track each revision of a Deployment and easily roll back to a previous stable version if issues arise.
- Zero-Downtime Updates: Gradually update your application using a rolling update strategy without service interruption.
- Self-Healing: Deployments automatically replace Pod instances if they crash, are terminated, or are removed from a node, ensuring the specified number of Pods are always available.

**How it works**:

1. You define the desired state of your application through a Deployment (e.g., which image to use, how many replicas to run).
2. The Deployment creates a ReplicaSet to ensure the specified number of Pods are running.
3. The ReplicaSet creates and manages the actual Pod instances.
4. When you update a Deployment (e.g., change the image version), the Deployment creates a new ReplicaSet and gradually replaces the old Pods with new ones according to the predefined rolling update strategy until all new Pods are running, then it removes the old ReplicaSet.

## Creating Deployments

### Creating a Deployment by using CLI

#### Prerequisites

- Ensure you have `kubectl` configured and connected to your cluster.

#### YAML file example

```yaml
# example-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment # Name of the Deployment
  labels:
    app: nginx   # Labels for identification and selection
spec:
  replicas: 3    # Desired number of Pod replicas
  selector:
    matchLabels:
      app: nginx  # Selector to match Pods managed by this Deployment
  template:
    metadata:
      labels:
        app: nginx          # Pod's labels, must match selector.matchLabels
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2 # Container image
        ports:
        - containerPort: 80 # Container exposed port
        resources:          # Resource limits and requests
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
```

#### Creating a Deployment via YAML

```bash
# Step 1: Create Deployment via yaml 
kubectl apply -f example-deployment.yaml 

# Step 2: Check the Deployment status
kubectl get deployment example-deployment.yaml # View Deployment
kubectl get pod -l app=nginx # View Pods created by this Deployment
```

### Creating a Deployment by using web console

#### Prerequisites

Obtain the image address. The source of the images can be from the image repository integrated by the platform administrator through the toolchain or from third-party platforms' image repositories.

- For the former, the Administrator typically assigns the image repository to your project, and you can use the images within it. If the required image repository is not found, please contact the Administrator for allocation.

- If it is a third-party platform's image repository, ensure that images can be pulled directly from it in the current cluster.

<a id="updatepolicy" />
#### Procedure - Configure Basic Info

1. **Container Platform**, navigate to **Workloads** > **Deployments** in the left sidebar. 

2. Click on **Create Deployment**.

3. **Select** or **Input** an image, and click **Confirm**.

:::info
   **Note**: When using images from the image repository integrated into web console, you can filter images by **Already Integrated**. The **Integration Project Name**, for example, images (docker-registry-projectname), which includes the project name projectname in this web console and the project name containers in the image repository.
:::

4. In the **Basic Info** section, configure declarative parameters for Deployment workloads: 

   | **Parameters**                 | **Description**     |
   | :----------------------------- | :-------------------- |
   | **Replicas**                   | Defines the desired number of Pod replicas in the Deployment (default: `1`). Adjust based on workload requirements. |
   | **More** > **Update Strategy** | Configures the `rollingUpdate` strategy for zero-downtime deployments: <br/> **Max surge** (`maxSurge`): <ul><li>Maximum number of Pods that can exceed the desired replica count during an update. </li><li> Accepts absolute values (e.g., `2`) or percentages (e.g., `20%`). </li><li> Percentage calculation: `ceil(current_replicas × percentage)`. </li><li>Example: 4.1 → `5` when calculated from 10 replicas. </li></ul> **Max unavailable** (`maxUnavailable`): <ul><li> Maximum number of Pods that can be temporarily unavailable during an update. </li><li>Percentage values cannot exceed `100%`. </li><li>Percentage calculation: `floor(current_replicas × percentage)`. </li><li> Example: 4.9 → `4` when calculated from 10 replicas. </li></ul> **Notes**: <br/> 1. **Default values**: `maxSurge=1`, `maxUnavailable=1` if not explicitly set. <br/> 2. **Non-running Pods** (e.g., in `Pending`/`CrashLoopBackOff` states) are considered unavailable. <br/> 3. **Simultaneous constraints**: <ul><li> `maxSurge` and `maxUnavailable` cannot both be `0` or `0%`. </li><li>If percentage values resolve to `0` for both parameters, Kubernetes forces `maxUnavailable=1` to ensure update progress. </li></ul> **Example**: <br/> For a Deployment with 10 replicas: <br/><ul><li> `maxSurge=2` → Total Pods during update: `10 + 2 = 12`. </li><li>`maxUnavailable=3` → Minimum available Pods: `10 - 3 = 7`. </li><li> This ensures availability while allowing controlled rollout. </li></ul> |

<a id="configurepod" />
#### Procedure - Configure Pod

**Note**: In mixed-architecture clusters deploying single-architecture images, ensure proper [Node Affinity Rules](#schuconf) are configured for Pod scheduling.

1. **Pod** section, configure container runtime parameters and lifecycle management: 

   | **Parameters**         | **Description**  |
   | :--------------------- | :---------------- |
   | **Volumes**            | Mount persistent volumes to containers. Supported volume types include `PVC`, `ConfigMap`, `Secret`,`emptyDir`, `hostPath`, and so on. For implementation details, see [Volume Mounting Guide](#pvmount).                                                                                               |
   | **Image Credential**   | Required **only** when pulling images from third-party registries (via manual image URL input). <br /> **Note**: Images from the platform's integrated registry automatically inherit associated secrets.                                                                                               |
   | **Close Grace Period** | Duration (default: `30s`) allowed for a Pod to complete graceful shutdown after receiving termination signal. <br /> - During this period, the Pod completes inflight requests and releases resources. <br /> - Setting `0` forces immediate deletion (SIGKILL), which may cause request interruptions. |

<a id="schuconf" />
2. **Node Affinity Rules**

| **Parameters**    | **Description**                                        |
| :----------------- | :----------------------------------------------------- |
| **More** > **Node Selector**   | Constrain Pods to nodes with specific labels (e.g. `kubernetes.io/os: linux`). <br/> ![Node OS Selector](./assets/nodeselector_os.png) | 
| **More** > **Affinity**  | Define fine-grained scheduling rules based on existing.<br/>**Pod Affinity Types**:<ul><li>**Inter-Pod Affinity**: Schedule new Pods to nodes hosting specific Pods(same topology domain).</li><li>**Inter-Pod Anti-affinity**: Prevent co-location of new Pods with specific Pods.</li></ul> **Enforcement Modes**:<ul><li> **RequiredDuringSchedulingIgnoredDuringExecution**: Pods are scheduled *only* if rules are satisfied.</li><li> **PreferredDuringSchedulingIgnoredDuringExecution**: Prioritize nodes meeting rules, but allow exceptions.</li></ul> **Configuration Fields**: <ul><li>`topologyKey`: Node label defining topology domains (default:`kubernetes.io/hostname`).{" "}</li><li>`labelSelector`: Filters target Pods using label queries. </li></ul> |

3. **Network Configuration**
   - Kube-OVN  
      | **Parameters** | **Description** |
      |:--------------------------|:--------------------------|
      | **Bandwidth Limits** | Enforce QoS for Pod network traffic:  <ul><li>**Egress rate limit**: Maximum outbound traffic rate (e.g., `10Mbps`). </li><li>**Ingress rate limit**: Maximum inbound traffic rate.</li></ul> |  
      | **Subnet** | Assign IPs from a predefined subnet pool. If unspecified, uses the namespace's default subnet. |  
      | **Static IP Address** | Bind persistent IP addresses to Pods:  <ul><li>Multiple Pods across Deployments can claim the same IP, but only one Pod can use it concurrently.  </li><li>**Critical**: Number of static IPs must ≥ Pod replica count. </li></ul>| 
   
   - Calico  
      | **Parameters** | **Description** |
      |:--------------------------|:--------------------------|
      | **Static IP Address**     | Assign fixed IPs with strict uniqueness:  <ul><li>Each IP can be bound to **only one Pod** in the cluster.  </li><li> **Critical**: Static IP count must ≥ Pod replica count.</li></ul> |

<a id="configurecontainers" />
#### Procedure - Configure Container

1. **Container** section, refer to the following instructions to configure the relevant information.

   | **Parameters**                         | **Description**     |
   | :------------------------------------- | :------------------------------------------------------|
   | **Resource Requests & Limits**         | <ul><li>**Requests**: Minimum CPU/memory required for container operation.</li><li>**Limits**: Maximum CPU/memory allowed during container execution. For unit definitions, see [Resource Units](/developer/overview/concepts/unit.mdx).</li></ul>**Namespace overcommit ratio**:<ul><li>**Without overcommit ratio**:<br />If namespace resource quotas exist: Container requests/limits inherit namespace defaults (modifiable).<br /> No namespace quotas: No defaults; custom Request.</li><li>**With overcommit ratio**:<br />Requests auto-calculated as `Limits / Overcommit ratio` (immutable).</li></ul> **Constraints**:<ul><li>Request ≤ Limit ≤ Namespace quota maximum.</li><li>Overcommit ratio changes require pod recreation to take effect.</li><li>Overcommit ratio disables manual request configuration.</li><li>No namespace quotas → no container resource constraints.</li></ul> |
   | **Extended Resources**                 | Configure cluster-available extended resources (e.g., vGPU, pGPU).|
   | **Volume Mount**                       | Persistent storage configuration. See [Storage Volume Mounting Instructions](#pvmount).<br />**Operations**:<ul><li>Existing pod volumes: Click **Add**</li><li>No pod volumes: Click **Add & Mount**</li></ul>**Parameters**:<ul><li>`mountPath`: Container filesystem path (e.g., `/data`)</li><li>`subPath`: Relative file/directory path within volume.<br /> For `ConfigMap`/`Secret`: Select specific key</li><li>`readOnly`: Mount as read-only (default: read-write)</li></ul>See [Kubernetes Volumes](https://kubernetes.io/docs/concepts/storage/volumes/). |
   | **Port**                               | Expose container ports.<br />**Example**: Expose TCP port `6379` with name `redis`.<br />**Fields**:<ul><li>`protocol`: TCP/UDP</li><li>`Port`: Exposed port (e.g., `6379`)</li><li>`name`: DNS-compliant identifier (e.g., `redis`)</li></ul>  |
   | **Startup Commands & Arguments**       | Override default ENTRYPOINT/CMD:<br />**Example 1**: Execute `top -b`<br />- **Command**: `["top", "-b"]`<br />- **OR** Command: `["top"]`, Args: `["-b"]`<br />**Example 2**: Output `$MESSAGE`:<br />`/bin/sh -c "while true; do echo $(MESSAGE); sleep 10; done"`<br />See [Defining Commands](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/). |
   | **More** > **Environment Variables**   | <ul><li>Static values: Direct key-value pairs</li><li>Dynamic values: Reference ConfigMap/Secret keys, pod fields (`fieldRef`), resource metrics (`resourceFieldRef`)</li></ul>**Note**: Env variables override image/configuration file settings. |
   | **More** > **Referenced ConfigMap**    | Inject entire ConfigMap/Secret as env variables. Supported Secret types: `Opaque`, `kubernetes.io/basic-auth`.|
   | **More** > **Health Checks**           | <ul><li>**Liveness Probe**: Detect container health (restart if failing)</li><li>**Readiness Probe**: Detect service availability (remove from endpoints if failing)</li></ul>See [Health Check Parameters](/developer/building_application/functions/application_operation/healthcheck.mdx#healthcheckparameters).  |
   | **More** > **Log File**                | Configure log paths:<br />- Default: Collect `stdout`<br />- File patterns: e.g., `/var/log/*.log`<br />**Requirements**:<ul><li>Storage driver `overlay2`: Supported by default</li><li>`devicemapper`: Manually mount EmptyDir to log directory</li><li>Windows nodes: Ensure parent directory is mounted (e.g., `c:/a` for `c:/a/b/c/*.log`)</li></ul>  |
   | **More** > **Exclude Log File**        | Exclude specific logs from collection (e.g., `/var/log/aaa.log`).  |
   | **More** > **Execute before Stopping** | Execute commands before container termination.<br />**Example**: `echo "stop"`<br />**Note**: Command execution time must be shorter than pod's `terminationGracePeriodSeconds`.  |

2. Click **Add Container** (upper right) OR **Add Init Container**.

   See [Init Containers](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/).
   Init Container:
      1. Start before app containers (sequential execution).
      2. Release resources after completion.
      3. Deletion allowed when: 
         - Pod has >1 app container AND ≥1 init container.
         - Not allowed for single-app-container pods.

3. Click **Create**.

#### Reference Information​

<a id="pvmount" />

##### Storage Volume Mounting instructions

| **Type**                    | **Purpose**     |
| --------------------------- | ---------------------- |
| **Persistent Volume Claim** | Binds an existing [PVC](/configure/storage/functions/create_pvc.mdx) to request persistent storage.<br /><br /><strong>Note</strong>: Only bound PVCs (with associated PV) are selectable. Unbound PVCs will cause pod creation failures.                                                                   |
| **ConfigMap**               | Mounts full/partial [ConfigMap](/developer/building_application/functions/preparation_before_creating/add_configmap.mdx) data as files:<ul><li>Full ConfigMap: Creates files named after keys under mount path</li><li>Subpath selection: Mount specific key (e.g., <code>my.cnf</code>)</li></ul>          |
| **Secret**                  | Mounts full/partial [Secret](/developer/building_application/functions/preparation_before_creating/add_secret.mdx) data as files:<ul><li>Full Secret: Creates files named after keys under mount path</li><li>Subpath selection: Mount specific key (e.g., <code>tls.crt</code>)</li></ul>                  |
| **Ephemeral Volumes**       | Cluster-provisioned temporary volume with features:<ul><li>Dynamic provisioning</li><li>Lifecycle tied to pod</li><li>Supports declarative configuration</li></ul><br /><strong>Use Case</strong>: Temporary data storage. See [Ephemeral Volumes](/configure/storage/how_to/generic_ephemeral_volumes.mdx) |
| **Empty Directory**         | Ephemeral storage sharing between containers in same pod:<br />- Created on node when pod starts<br />- Deleted with pod removal<br /><br /><strong>Use Case</strong>: Inter-container file sharing, temporary data storage. See [EmptyDir](/configure/storage/how_to/using_empty_dir.mdx)                  |
| **Host Path**               | Mounts host machine directory (must start with `/`, e.g., `/volumepath`).        |

#### Heath Checks

 - [Health checks YAML file example](/developer/building_application/functions/application_operation/healthcheck.mdx#healthcheckyamlexample)
 - [Health checks configuration parameters in web console](/developer/building_application/functions/application_operation/healthcheck.mdx#healthcheckparameters)

## Managing Deployments

### Managing a Deployment by using CLI

#### Viewing a Deployment

- Check the Deployment was created.
```bash
 kubectl get deployments
 ```
- Get details of your Deployment.
```bash
kubectl describe deployments
```

#### Updating a Deployment

Follow the steps given below to update your Deployment:

1. Let's update the nginx Pods to use the nginx:1.16.1 image.
```bash
kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1
```
or use the following command:
```bash
kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1
```

Alternatively, you can edit the Deployment and change `.spec.template.spec.containers[0].image` from `nginx:1.14.2` to `nginx:1.16.1`:
```bash
kubectl edit deployment/nginx-deployment
```
2. To see the rollout status, run:
```bash
kubectl rollout status deployment/nginx-deployment
```
   - Run kubectl get rs to see that the Deployment updated the Pods by creating a new ReplicaSet and scaling it up to 3 replicas, as well as scaling down the old ReplicaSet to 0 replicas.

   ```bash
   kubectl get rs
   ```
   - Running get pods should now show only the new Pods:
   ```bash
   kubectl get pods
   ```

#### Scaling a Deployment

You can scale a Deployment by using the following command:

```bash
kubectl scale deployment/nginx-deployment --replicas=10
```

#### Rolling Back a Deployment

- Suppose that you made a typo while updating the Deployment, by putting the image name as `nginx:1.161` instead of `nginx:1.16.1`:
```bash
kubectl set image deployment/nginx-deployment nginx=nginx:1.161
```
- The rollout gets stuck. You can verify it by checking the rollout status:
```bash
kubectl rollout status deployment/nginx-deployment
```

#### Deleting a Deployment

Deleting a Deployment will also delete its managed ReplicaSet and all associated Pods.

```bash
kubectl delete deployment <deployment-name>
```

### Managing a Deployment by using web console

### Viewing a Deployment

You can view a deployment to get information of your application.

1. **Container Platform**, and navigate to **Workloads** > **Deployments**.
2. Locate the Deployment you wish to view.
3. Click the deployment name to see the **Details**, **Topology**, **Logs**, **Events**, **Monitoring**, etc.

#### Updating a Deployment

1. **Container Platform**, and navigate to **Workloads** > **Deployments**.
2. Locate the Deployment you wish to update.
3. In the **Actions** drop-down menu, select **Update** to view the Edit Deployment page.

#### Deleting a Deployment

1. **Container Platform**, and navigate to **Workloads** > **Deployments**.
2. Locate the Deployment you wish to delete.
3. In the **Actions** drop-down menu, Click the **Delete** button in the operations column and confirm.


## Troubleshooting by using CLI

When a Deployment encounters issues, here are some common troubleshooting methods.

### Check Deployment status

```bash
kubectl get deployment nginx-deployment
kubectl describe deployment nginx-deployment # View detailed events and status
```
### Check ReplicaSet status

```bash
kubectl get rs -l app=nginx
kubectl describe rs <replicaset-name>
```

### Check Pod status
```bash
kubectl get pods -l app=nginx
kubectl describe pod <pod-name>
```

### View Logs
```bash
kubectl logs <pod-name> -c <container-name> # View logs for a specific container
kubectl logs <pod-name> --previous         # View logs for the previously terminated container
```
### Enter Pod for debugging
```
kubectl exec -it <pod-name> -- /bin/bash # Enter the container shell
```

### Check Health Check configuration
Ensure livenessProbe and readinessProbe are correctly configured, and your application's health check endpoints are responding properly. [Troubleshooting probe failures](/developer/building_application/functions/application_operation/healthcheck.mdx#healthchecktroubleshooting)


### Check Resource Limits
Ensure container resource requests and limits are reasonable and that containers are not being killed due to insufficient resources.