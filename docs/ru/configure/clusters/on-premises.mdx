---
weight: 20
title: Создание локального кластера
sourceSHA: eac53df4fa3274ff6635e9b301e013fd01f958fe4e72c72ef445b765d88d660b
---

# Создание локального кластера

## Предварительные условия

### Требования к узлам

1. Если вы скачали установочный пакет с единой архитектурой с [Загрузить установочный пакет](/install/prepare/download.mdx#download_installation_package), убедитесь, что архитектура ваших узлов соответствует архитектуре пакета. В противном случае узлы не запустятся из-за отсутствия изображений, специфичных для этой архитектуры.
2. Убедитесь, что ваша операционная система узла и ядро поддерживаются. Смотрите [Поддерживаемые операционные системы и ядра](/install/prepare/prerequisites.mdx#supported_os_and_kernels) для получения подробной информации.
3. Проведите проверки доступности на узлах. Для конкретных элементов проверки обратитесь к [Предварительная обработка узла > Проверки узлов](/install/prepare/node_preprocessing.mdx#node_checks).
4. Если IP-адреса узлов не могут быть напрямую доступны через SSH, предоставьте прокси-сервер SOCKS5 для узлов. Кластер `global` будет получать доступ к узлам через эту прокси-службу.

### Балансировка нагрузки

Для производственных сред требуется балансировщик нагрузки для узлов управляющей плоскости кластера, чтобы обеспечить высокую доступность. Вы можете использовать свой собственный аппаратный балансировщик нагрузки или включить `Самостоятельно созданный VIP`, который предоставляет программную балансировку нагрузки с использованием haproxy + keepalived. Мы рекомендуем использовать аппаратный балансировщик нагрузки, так как:

- **Лучшая производительность**: Аппаратная балансировка нагрузки работает лучше, чем программная.
- **Низкая сложность**: Если вы не знакомы с keepalived, неправильная конфигурация может сделать кластер недоступным, что приведет к длительному устранению неполадок и серьезно повлияет на надежность кластера.

При использовании вашего собственного аппаратного балансировщика нагрузки вы можете использовать VIP балансировщика нагрузки в качестве параметра `IP-адрес / доменное имя`. Если у вас есть доменное имя, которое разрешается в VIP балансировщика, вы можете использовать это доменное имя в качестве параметра `IP-адрес / доменное имя`. Обратите внимание:

- Балансировщик нагрузки должен правильно перенаправлять трафик на порты `6443`, `11780` и `11781` на всех узлах управляющей плоскости в кластере.
- Если ваш кластер имеет только один узел управляющей плоскости, и вы используете IP этого узла в качестве параметра `IP-адрес / доменное имя`, кластер не может быть увеличен от одного узла до высокодоступной многопользовательской настройки в дальнейшем. Поэтому мы рекомендуем предоставлять балансировщик нагрузки даже для кластеров с одним узлом.

При включении `Самостоятельно созданного VIP` вам необходимо подготовить:

1. Доступный VRID
2. Хостовую сеть, поддерживающую протокол VRRP
3. Все узлы управляющей плоскости и VIP должны находиться в одной подсети, а VIP должен отличаться от любого IP узла.

### Связывание кластера `global` и рабочего кластера

Платформа требует взаимного доступа между кластером `global` и рабочими кластерами. Если они не находятся в одной сети, вам необходимо:

1. Обеспечить `Внешний доступ` для рабочего кластера, чтобы гарантировать, что кластер `global` может получить к нему доступ. Сетевые требования должны гарантировать, что `global` может получить доступ к портам `6443`, `11780` и `11781` на всех узлах управляющей плоскости.
2. Добавить дополнительный адрес к `global`, которому может получить доступ рабочий кластер. При создании рабочего кластера добавьте этот адрес в аннотации кластера с ключом `cpaas.io/platform-url` и значением, установленным на общедоступный адрес доступа `global`.

### Регистр изображений

Изображения кластера поддерживают варианты платформенных встроенных, частных репозиториев и публичных репозиториев.

- **Платформенная встроенная**: Использует реестр изображений, предоставленный кластером `global`. Если кластер не может получить доступ к `global`, смотрите [Добавить внешний адрес для встроенного реестра](/configure/clusters/how-to/add_external_addr_for_global_registry.mdx).
- **Частный репозиторий**: Использует ваш собственный реестр изображений. Для получения подробной информации о загрузке необходимых изображений в ваш реестр свяжитесь с технической поддержкой.
- **Публичный репозиторий**: Использует публичный реестр изображений платформы. Перед использованием завершите [Обновление учетных данных публичного репозитория](/configure/clusters/how-to/update_public_repository_credentials.mdx).

### Сетевое подключение контейнеров

Если вы планируете использовать Kube-OVN Underlay для вашего кластера, обратитесь к [Подготовка физической сети Kube-OVN Underlay](/configure/networking/how_to/kubeovn_underlay_py.mdx).

## Процедура создания

1. Перейдите в представление **Управление платформой** и нажмите **Кластеры/Кластеры** в левом навигационном меню.

2. Нажмите **Создать кластер**.

3. Настройте следующие разделы в соответствии с приведенными ниже инструкциями: Основная информация, Сетевая инфраструктура контейнеров, Настройки узлов и Расширенные параметры.

### Основная информация

<table>
  <tr>
    <th style={{ whiteSpace: 'nowrap' }}>Параметр</th>
    <th style={{ whiteSpace: 'nowrap' }}>Описание</th>
  </tr>

  <tr>
    <td><b>Версия Kubernetes</b></td>

    <td>
      Все дополнительные версии тщательно тестируются на стабильность и совместимость.<br />
      <b>Рекомендация:</b> Выберите последнюю версию для оптимальных функций и поддержки.
    </td>
  </tr>

  <tr>
    <td><b>Рuntime контейнеров</b></td>

    <td>
      Containerd предоставляется в качестве стандартного runtime контейнеров.<br />
      Если вы предпочитаете использовать Docker в качестве runtime контейнеров, пожалуйста, обратитесь к [Выбору runtime контейнера](/configure/clusters/how-to/choose_cri.mdx).
    </td>
  </tr>

  <tr>
    <td><b>Протокол сетевой инфраструктуры кластера</b></td>

    <td>
      Поддерживает три режима: IPv4 единожды, IPv6 единожды, IPv4/IPv6 двойной стек.<br />
      <b>Примечание:</b> Если вы выберете режим двойного стека, убедитесь, что все узлы имеют правильно настроенные IPv6 адреса; сетевой протокол не может быть изменен после настройки.
    </td>
  </tr>

  <tr>
    <td><b>Точка доступа к кластеру</b></td>

    <td>
      <code>IP-адрес / доменное имя</code>: Введите заранее подготовленное доменное имя или VIP, если доменное имя недоступно.<br />
      <code>Самостоятельно созданный VIP</code>: Отключен по умолчанию. Включайте только если не предоставлен LoadBalancer. Когда включен, установщик автоматически развернет <code>keepalived</code> для поддержки программной балансировки нагрузки.<br />
      <code>Внешний доступ</code>: Введите адрес внешнего доступа, подготовленный для кластера, когда он находится не в одной сетевой среде с кластером <code>global</code>.
    </td>
  </tr>
</table>

### Сетевая инфраструктура контейнеров

<Tabs>
  <Tab label="Kube-OVN">
    Корпоративная система оркестрации сетевой инфраструктуры контейнеров Kubernetes, разработанная Alauda. Она привносит зрелые сетевые возможности из области OpenStack в Kubernetes, поддерживая управление сетями между облаками, традиционной сетевой архитектурой и инфраструктурой, а также сценариями развертывания крайних кластеров, при этом значительно повышая безопасность сети контейнеров Kubernetes, эффективность управления и производительность.

    <table>
      <tr>
        <th style={{ whiteSpace: 'nowrap' }}>Параметр</th>
        <th style={{ whiteSpace: 'nowrap' }}>Описание</th>
      </tr>

      <tr>
        <td><b>Подсеть</b></td>

        <td>
          Также известна как Cluster CIDR, представляет собой <b>сегмент подсети по умолчанию</b>. После создания кластера могут быть добавлены дополнительные подсети.
        </td>
      </tr>

      <tr>
        <td><b>Режим передачи</b></td>

        <td>
          <b>Overlay</b>: Виртуальная сеть, абстрагированная от инфраструктуры, которая не потребляет физические сетевые ресурсы. При создании подсетки Overlay по умолчанию все подсети Overlay в кластере используют одну и ту же конфигурацию сетевого интерфейса кластера и интерфейса узла.<br />
          <b>Underlay</b>: Этот способ передачи зависит от физических сетевых устройств. Он может напрямую выделять физические сетевые адреса для Pods, обеспечивая лучшую производительность и подключаемость с физической сетью. Узлы в подсети Underlay должны иметь несколько NIC, и NIC, используемый для мостовой сети, должен использоваться исключительно Underlay и не должен нести другой трафик, такой как SSH. При создании подсетки Underlay по умолчанию, сетевой интерфейс кластера фактически является стандартным NIC для мостовой сети, а сетевой интерфейс узла — это конфигурация сетевого интерфейса узла в мостовой сети.<br />

          - <b>Стандартный шлюз</b>: Адрес шлюза физической сети, который является адресом шлюза для сегмента Cluster CIDR (должен находиться в пределах диапазона адресов Cluster CIDR).<br />
          - <b>Идентификатор VLAN</b>: Идентификатор виртуальной локальной сети (номер VLAN), например, <code>0</code>.<br />
          - <b>Зарезервированные IP</b>: Установите зарезервированные IP, которые не будут автоматически выделяться, такие как IP в подсети, которые уже используются другими устройствами.
        </td>
      </tr>

      <tr>
        <td><b>Service CIDR</b></td>

        <td>
          Диапазон IP-адресов, используемый службами Kubernetes типа ClusterIP. Не может пересекаться с диапазоном подсетей по умолчанию.
        </td>
      </tr>

      <tr>
        <td><b>Join CIDR</b></td>

        <td>
          В режиме передачи Overlay это диапазон IP-адресов, используемый для связи между узлами и Pods. Не может пересекаться с подсетью по умолчанию или Service CIDR.
        </td>
      </tr>
    </table>
  </Tab>

  <Tab label="Calico">
    Calico — это решение для сетевого взаимодействия на уровне 3, которое обеспечивает безопасные сетевые подключения для контейнеров.

    <table>
      <tr>
        <th style={{ whiteSpace: 'nowrap' }}>Параметр</th>
        <th style={{ whiteSpace: 'nowrap' }}>Описание</th>
      </tr>

      <tr>
        <td><b>Стандартная подсеть</b></td>

        <td>
          Также известна как Cluster CIDR, представляет собой <b>сегмент подсети по умолчанию</b>. После создания кластера могут быть добавлены дополнительные подсети.
        </td>
      </tr>

      <tr>
        <td><b>Service CIDR</b></td>

        <td>
          Диапазон IP-адресов, используемый службами Kubernetes типа ClusterIP. Не может пересекаться с диапазоном подсетей по умолчанию.
        </td>
      </tr>
    </table>
  </Tab>

  <Tab label="Flannel">
    Flannel обеспечивает плоскую сетевую среду для всех контейнеров в кластере, предоставляя контейнерам, созданным на разных узловых хостах, уникальный виртуальный IP-адрес по всему кластеру. Подсеть POD равномерно распределяется среди узлов кластера в соответствии с маской, а Pods на каждом узле получают IP-адреса из сегмента, выделенного этому узлу. Это повышает эффективность общения между контейнерами без необходимости учитывать вопросы перевода IP.

    <table>
      <tr>
        <th style={{ whiteSpace: 'nowrap' }}>Параметр</th>
        <th style={{ whiteSpace: 'nowrap' }}>Описание</th>
      </tr>

      <tr>
        <td><b>Cluster CIDR</b></td>

        <td>
          Диапазон IP-адресов, используемый Pods, созданными при запуске кластера. Поддерживает установку максимально допустимого количества IP-адресов, которые могут быть выделены Pods на каждом узле в текущей контейнерной сети.<br />
          <b>Примечание</b>: Платформа автоматически вычислит максимальное количество узлов, которые может вместить кластер, основываясь на вышеуказанной конфигурации, и отобразит это в подсказке под полем ввода.<br />
          <b>Важно</b>: После создания кластера менять сетевую инфраструктуру кластера нельзя, поэтому тщательно планируйте сеть.
        </td>
      </tr>

      <tr>
        <td><b>Service CIDR</b></td>

        <td>
          Диапазон IP-адресов, используемый службами Kubernetes типа ClusterIP. Не может пересекаться с диапазоном подсетей контейнера.
        </td>
      </tr>
    </table>
  </Tab>

  <Tab label="Настройка">
    Если вам нужно установить другие сетевые плагины, выберите режим <b>Настройка</b>. Вы можете вручную установить сетевые плагины после успешного создания кластера.

    <table>
      <tr>
        <th style={{ whiteSpace: 'nowrap' }}>Параметр</th>
        <th style={{ whiteSpace: 'nowrap' }}>Описание</th>
      </tr>

      <tr>
        <td><b>Cluster CIDR</b></td>

        <td>
          Диапазон IP-адресов, используемый Pods, созданными при запуске кластера.
        </td>
      </tr>

      <tr>
        <td><b>Service CIDR</b></td>

        <td>
          Диапазон IP-адресов, используемый службами Kubernetes типа ClusterIP. Не может пересекаться с диапазоном подсетей контейнера.
        </td>
      </tr>
    </table>
  </Tab>
</Tabs>

### Настройки узлов

<table>
  <tr>
    <th style={{ whiteSpace: 'nowrap' }}>Параметр</th>
    <th style={{ whiteSpace: 'nowrap' }}>Описание</th>
  </tr>

  <tr>
    <td><b>Сетевой интерфейс карты</b></td>

    <td>
      Имя устройства сетевого интерфейса хоста, используемого плагином сетевой инфраструктуры кластера.<br />
      <b>Примечание</b>:<br />

      - При выборе режима передачи Underlay для стандартной подсети Kube-OVN вы должны указать имя сетевого интерфейса, который будет стандартным NIC для мостовой сети.<br />
      - Мониторинг трафика сетевого интерфейса платформы по умолчанию распознает трафик на интерфейсах с именами вроде <code>eth.|en.|wl.*|ww.*</code>. Если вы используете интерфейсы с другими соглашениями об именах, пожалуйста, обратитесь к [Сбор данных сети с пользовательских имен сетевых интерфейсов](/observability/monitor/how_to/special_network_card_name.mdx) после присоединения кластера, чтобы изменить соответствующие ресурсы и убедиться, что платформа может правильно следить за трафиком сетевого интерфейса.
    </td>
  </tr>

  <tr>
    <td><b>Имя узла</b></td>

    <td>
      Вы можете выбрать использовать либо IP-адрес узла, либо имя хоста в качестве имени узла на платформе.<br />
      <b>Примечание</b>: При выборе использования имени хоста в качестве имени узла убедитесь, что имена хостов узлов, добавленных в кластер, уникальны.
    </td>
  </tr>

  <tr>
    <td><b>Узлы</b></td>

    <td>
      <b>Добавьте узлы</b> в кластер или <b>Восстановите из черновика</b> временно сохраненную информацию об узлах. См. подробные описания параметров для добавления узлов ниже.
    </td>
  </tr>

  <tr>
    <td><b>Тип мониторинга</b></td>

    <td>
      Поддерживает <b>Prometheus</b> и <b>VictoriaMetrics</b>.<br />
      При выборе <b>VictoriaMetrics</b> в качестве компонента мониторинга необходимо настроить <b>Тип развертывания</b>:<br />
      <b>- Развернуть VictoriaMetrics</b>: Разворачивает все связанные компоненты, включая <b>VMStorage</b>, <b>VMAlert</b>, <b>VMAgent</b> и т. д.<br />
      <b>- Развернуть VictoriaMetrics Agent</b>: Разворачивает только компонент сбора логов <b>VMAgent</b>. При использовании этого способа развертывания необходимо связаться с экземпляром VictoriaMetrics, который уже развёрнут на другом кластере в платформе, для предоставления услуг мониторинга кластеру.
    </td>
  </tr>

  <tr>
    <td><b>Мониторинг узлов</b></td>

    <td>
      Выберите узлы для развертывания компонентов мониторинга кластера. Поддерживает выбор вычислительных узлов и узлов управляющей плоскости, которые допускают развертывание приложений.<br />
      Чтобы избежать влияния на производительность кластера, рекомендуется отдать предпочтение вычислительным узлам. После успешного создания кластера компоненты мониторинга с типом хранилища <b>Local Volume</b> будут развернуты на выбранных узлах.
    </td>
  </tr>
</table>

**Параметры добавления узлов**

<table>
  <tr>
    <th style={{ whiteSpace: 'nowrap' }}>Параметр</th>
    <th style={{ whiteSpace: 'nowrap' }}>Описание</th>
  </tr>

  <tr>
    <td><b>Тип</b></td>

    <td>
      <b>Узел управляющей плоскости</b>: Ответственен за запуск компонентов, таких как kube-apiserver, kube-scheduler, kube-controller-manager, etcd, контейнерная сеть и некоторые компоненты управления платформой в кластере. Когда включен <b>Развертываемое приложение</b>, узлы управляющей плоскости также могут быть использованы в качестве вычислительных узлов.<br />
      <b>Рабочий узел</b>: Ответственен за размещение бизнес-подов, работающих в кластере.
    </td>
  </tr>

  <tr>
    <td><b>IPv4-адрес</b></td>

    <td>
      IPv4-адрес узла. Для кластеров, созданных в режиме внутренней сети, введите <b>приватный IP</b> узла.
    </td>
  </tr>

  <tr>
    <td><b>IPv6-адрес</b></td>

    <td>
      Действителен, когда в кластере включен двойной стек IPv4/IPv6. IPv6-адрес узла.
    </td>
  </tr>

  <tr>
    <td><b>Развертываемое приложение</b></td>

    <td>
      Действительно, когда <b>Тип узла</b> это <b>Узел управляющей плоскости</b>. Может ли бизнес-приложение быть развернуто на этом узле управляющей плоскости, планируя бизнес-подсы на этот узел.
    </td>
  </tr>

  <tr>
    <td><b>Имя для отображения</b></td>

    <td>
      Имя для отображения узла.
    </td>
  </tr>

  <tr>
    <td><b>IP для SSH-подключения</b></td>

    <td>
      IP-адрес, который может подключиться к узлу при доступе к нему через службу SSH.<br />
      Если вы можете войти в узел, используя <code>ssh \<имя_пользователя>@\<IPv4-адрес узла></code>, этот параметр не требуется; в противном случае введите общий IP-адрес узла или внешний NAT IP, чтобы обеспечить доступ к узлу через этот IP для <code>global</code> кластера и прокси.
    </td>
  </tr>

  <tr>
    <td><b>Сетевой интерфейс карты</b></td>

    <td>
      Введите имя сетевого интерфейса, используемого узлом. Приоритет эффективности конфигурации сетевого интерфейса следующий (слева направо, в порядке убывания):<br />
      <b>Kube-OVN Underlay</b>: Node NIC > Cluster NIC<br />
      <b>Kube-OVN Overlay</b>: Node NIC > Cluster NIC > NIC, соответствующий маршруту по умолчанию узла<br />
      <b>Calico</b>: Cluster NIC > NIC, соответствующий маршруту по умолчанию узла<br />
      <b>Flannel</b>: Cluster NIC > NIC, соответствующий маршруту по умолчанию узла
    </td>
  </tr>

  <tr>
    <td><b>Связанные мостовые сети</b></td>

    <td>
      <b>Примечание</b>: При создании кластера конфигурация мостовой сети не поддерживается; этот вариант доступен только при <b>добавлении узлов</b> в кластер, в котором уже созданы подсети Underlay.<br />
      Выберите существующую [Добавить мостовую сеть](/configure/networking/functions/subnet_kubeovn_underlay.mdx#kube-ovn_underlay_bridge_network). Если вы не хотите использовать NIC по умолчанию для мостовой сети, вы можете отдельно настроить NIC узла.
    </td>
  </tr>

  <tr>
    <td><b>SSH-порт</b></td>

    <td>
      Номер порта службы SSH, например, <code>22</code>.
    </td>
  </tr>

  <tr>
    <td><b>Имя пользователя SSH</b></td>

    <td>
      Имя пользователя SSH, должно быть пользователем с правами root, например, <code>root</code>.
    </td>
  </tr>

  <tr>
    <td><b>Прокси</b></td>

    <td>
      Нужно ли получать доступ к порту SSH узла через прокси. Когда кластер <code>global</code> не может напрямую получить доступ к узлу, который необходимо добавить через SSH (например, кластер <code>global</code> и рабочий кластер не находятся в одной подсети; IP узла — это внутренний IP, к которому кластер <code>global</code> не может напрямую получить доступ), этот переключатель необходимо включить и настроить параметры, связанные с прокси. После настройки прокси можно получить доступ к узлу и осуществить развертывание через прокси.<br />
      <b>Примечание</b>: В настоящее время поддерживается только прокси SOCKS5.<br />
      <b>URL доступа</b>: Адрес прокси-сервера, например, <code>192.168.1.1:1080</code>.<br />
      <b>Имя пользователя</b>: Имя пользователя для доступа к прокси-серверу.<br />
      <b>Пароль</b>: Пароль для доступа к прокси-серверу.
    </td>
  </tr>

  <tr>
    <td><b>SSH-аутентификация</b></td>

    <td>
      Метод аутентификации и соответствующая информация для входа на добавленный узел. Варианты включают:<br />
      <b>Пароль</b>: Требуется имя пользователя с правами root и соответствующий <b>SSH-пароль</b>.<br />
      <b>Ключ</b>: Требуется <b>приватный ключ</b> с правами root и <b>пароль к приватному ключу</b>.
    </td>
  </tr>

  <tr>
    <td><b>Сохранить черновик</b></td>

    <td>
      Сохраняет текущие данные конфигурации в диалоге как черновик и закрывает диалог <b>Добавить узел</b>.<br />
      Не покидая страницу <b>Создать кластер</b>, вы можете выбрать <b>Восстановить из черновика</b>, чтобы открыть диалог <b>Добавить узел</b> и восстановить конфигурационные данные, сохраненные как черновик.<br />
      <b>Примечание</b>: Данные, восстановленные из черновика, являются самыми последними сохраненными данными черновика.
    </td>
  </tr>
</table>

### Расширенные параметры

**Примечание**:

- Кроме обязательных конфигураций, не рекомендуется устанавливать расширенные параметры, так как неправильные настройки могут сделать кластер недоступным, и их нельзя изменить после создания кластера.

- Если введенный **Ключ** дублирует Параметр **Ключ**, он заменит стандартную конфигурацию.

**Процедура**

1. Нажмите **Расширенные параметры**, чтобы развернуть область конфигурации расширенных параметров. Вы можете необязательно установить следующие расширенные параметры для кластера:

<table>
  <tr>
    <th style={{ whiteSpace: 'nowrap' }}>Параметр</th>
    <th style={{ whiteSpace: 'nowrap' }}>Описание</th>
  </tr>

  <tr>
    <td><b>Параметры Docker</b></td>

    <td>
      <code>dockerExtraArgs</code>, дополнительные параметры конфигурации для Docker, которые будут записаны в <code>/etc/sysconfig/docker</code>. Модификация не рекомендуется. Чтобы настроить Docker через файл <code>daemon.json</code>, его необходимо настроить в форме пар значений.
    </td>
  </tr>

  <tr>
    <td><b>Параметры Kubelet</b></td>

    <td>
      <code>kubeletExtraArgs</code>, дополнительные параметры конфигурации для Kubelet.<br />
      <b>Примечание</b>: Когда параметр <b>Число узлов IP в контейнерной сети</b> введен, автоматически генерируется стандартная конфигурация <b>Параметра Kubelet</b> с ключом <code>max-pods</code> и значением <b>Число узлов IP</b>. Он устанавливает максимальное количество Pods, которые могут работать на любом узле кластеров. Эта конфигурация не отображается в интерфейсе.<br />
      Добавление новой пары <code>max-pods: максимальное количество работающих Pods</code> в области <b>Параметры Kubelet</b> заменит стандартное значение. Разрешен любой положительный занчение, но рекомендуется использовать стандартное значение (Число узлов IP) или ввести значение, не превышающее <code>256</code>.
    </td>
  </tr>

  <tr>
    <td><b>Параметры менеджера контроллера</b></td>

    <td>
      <code>controllerManagerExtraArgs</code>, дополнительные параметры конфигурации для менеджера контроллера.
    </td>
  </tr>

  <tr>
    <td><b>Параметры диспетчера</b></td>

    <td>
      <code>schedulerExtraArgs</code>, дополнительные параметры конфигурации для диспетчера.
    </td>
  </tr>

  <tr>
    <td><b>Параметры APIServer</b></td>

    <td>
      <code>apiServerExtraArgs</code>, дополнительные параметры конфигурации для APIServer.
    </td>
  </tr>

  <tr>
    <td><b>URL APIServer</b></td>

    <td>
      <code>publicAlternativeNames</code>, адреса доступа к APIServer, выданные в сертификате. Можно вводить только IP-адреса или доменные имена, максимум 253 символа.
    </td>
  </tr>

  <tr>
    <td><b>Аннотации кластера</b></td>

    <td>
      Аннотации кластера, отмечающие характеристики кластера в метаданных в форме ключ-значение, чтобы компоненты платформы или бизнес-компоненты могли получать соответствующую информацию.
    </td>
  </tr>
</table>

4. Нажмите **Создать**. Вы вернетесь на страницу списка кластеров, где кластер будет в состоянии **Создание**.

## Шаги после создания

### Просмотр прогресса создания

На странице списка кластеров вы можете просмотреть список созданных кластеров. Для кластеров в состоянии **Создание** вы можете проверить выполнение процесса.

**Процедура**

1. Нажмите небольшую иконку **Просмотр хода выполнения** справа от статуса кластера.

2. В диалоге выполнения, который появляется, вы можете просмотреть прогресс выполнения кластера (status.conditions).

   **Совет**: Когда определенный тип выполняется или находится в состоянии сбоя с причиной, наведите курсор на соответствующую причину (показанную голубым текстом), чтобы получить подробную информацию о причине (status.conditions.reason).

### Связывание с проектами

После создания кластера вы можете добавить его в проекты в представлении управления проектами.
