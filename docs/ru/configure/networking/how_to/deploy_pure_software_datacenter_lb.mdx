---
weight: 10
sourceSHA: 24b0707835f7fce31df12c89259beabfcd6b96baea1ffd8d30656fde6d640050
---

# Решение для программного балансировщика нагрузки в центре обработки данных (Alpha)

Разверните чисто программный балансировщик нагрузки (LB) в центре обработки данных, создав высокодоступный балансировщик нагрузки вне кластера, предоставляющий возможности балансировки нагрузки для нескольких ALB, чтобы обеспечить стабильную работу бизнеса. Он поддерживает конфигурацию только для IPv4, только для IPv6 или двойной стек для IPv4 и IPv6.

## Предварительные условия

1. Подготовьте два или более узлов-хостов в качестве LB. Рекомендуется установить операционную систему Ubuntu 22.04 на узлах LB, чтобы сократить время перенаправления трафика на ненормальные узлы.

2. Предварительно установите следующее программное обеспечение на всех узлах-хостах внешнего LB (эта глава берет два узла хоста внешнего LB в качестве примера):

   - `ipvsadm`

   - `Docker (20.10.7)`

3. Убедитесь, что служба Docker запускается при загрузке для каждого узла, используя следующую команду: `sudo systemctl enable docker.service`.

4. Убедитесь, что часы каждого узла синхронизированы.

5. Подготовьте образ для Keepalived, используемый для запуска службы внешнего LB; на платформе уже имеется этот образ. Адрес образа имеет следующий формат: `<image repository address>/tkestack/keepalived:<version suffix>`. Суффикс версии может немного отличаться в разных версиях. Вы можете получить адрес репозитория образа и суффикс версии следующим образом. В этом документе используется `build-harbor.alauda.cn/tkestack/keepalived:v3.16.0-beta.3.g598ce923` в качестве примера.

   - В глобальном кластере выполните `kubectl get prdb base -o json | jq .spec.registry.address`, чтобы получить параметр **адреса репозитория образа**.

   - В каталоге, где извлечен установочный пакет, выполните `cat ./installer/res/artifacts.json |grep keepalived -C 2|grep tag|awk '{print $2}'|awk -F '"' '{print $2}'`, чтобы получить **суффикс версии**.

## Шаги

**Примечание**: Следующие операции необходимо выполнить один раз на каждом узле внешнего LB, и `hostname` узлов-хостов не должен повторяться.

1. Добавьте следующую конфигурационную информацию в файл `/etc/modules-load.d/alive.kmod.conf`.

   ```
   ip_vs
   ip_vs_rr
   ip_vs_wrr
   ip_vs_sh
   nf_conntrack_ipv4
   nf_conntrack
   ip6t_MASQUERADE
   nf_nat_masquerade_ipv6
   ip6table_nat
   nf_conntrack_ipv6
   nf_defrag_ipv6
   nf_nat_ipv6
   ip6_tables
   ```

2. Добавьте следующую конфигурационную информацию в файл `/etc/sysctl.d/alive.sysctl.conf`.

   ```
   net.ipv4.ip_forward = 1
   net.ipv4.conf.all.arp_accept = 1
   net.ipv4.vs.conntrack = 1
   net.ipv4.vs.conn_reuse_mode = 0
   net.ipv4.vs.expire_nodest_conn = 1
   net.ipv4.vs.expire_quiescent_template = 1
   net.ipv6.conf.all.forwarding=1
   ```

3. Перезагрузитесь, используя команду `reboot`.

4. Создайте папку для конфигурационного файла Keepalived.

   ```
   mkdir -p /etc/keepalived
   mkdir -p /etc/keepalived/kubecfg
   ```

5. Измените элементы конфигурации в соответствии с комментариями в следующем файле и сохраните их в папке `/etc/keepalived/`, назвав файл `alive.yaml`.

   ```
   instances:
     - vip: # Можно настроить несколько VIP
         vip: 192.168.128.118 # VIP должны быть разными
         id: 20 # ID каждого VIP должен быть уникальным, необязательный
         interface: "eth0"
         check_interval: 1 # необязательный, по умолчанию 1: интервал для выполнения скрипта проверки
         check_timeout: 3  # необязательный, по умолчанию 3: время ожидания скрипта проверки
         name: "vip-1" # Идентификатор этого экземпляра, может содержать только буквы и цифры, а также дефисы, не может начинаться с дефиса
         peer: [ "192.168.128.116", "192.168.128.75" ] # IP-адреса узлов Keepalived, фактический сгенерированный keepalived.conf удалит все IP-адреса на интерфейсе https://github.com/osixia/docker-keepalived/issues/33
         kube_lock:
           kubecfgs: # Список kube-config, используемый kube-lock, будет последовательно пытаться эти kubecfg для выборов лидеров в Keepalived
             - "/live/cfg/kubecfg/kubecfg01.conf"
             - "/live/cfg/kubecfg/kubecfg02.conf"
             - "/live/cfg/kubecfg/kubecfg03.conf"
       ipvs: # Конфигурация для опции IPVS
         ips: [ "192.168.143.192", "192.168.138.100","192.168.129.100" ] # IPVS бэкенд, измените IP адрес узла k8s master на IP адрес узла ALB
         ports: # Настройка логики проверки состояния для каждого порта на VIP
           - port: 80 # Порт на виртуальном сервере должен совпадать с портом реального сервера
             virtual_server_config: |
               delay_loop 10  # Интервал для выполнения проверок состояния на реальном сервере
               lb_algo rr
               lb_kind NAT
               protocol TCP
             raw_check: |
               TCP_CHECK {
                   connect_timeout 10
                   connect_port 1936
               }
     - vip:
         vip: 2004::192:168:128:118
         id: 102
         interface: "eth0"
         peer: [ "2004::192:168:128:75","2004::192:168:128:116" ]
         kube_lock:
           kubecfgs: # Список kube-config, используемый kube-lock, будет последовательно пытаться эти kubecfg для выборов лидеров в Keepalived
             - "/live/cfg/kubecfg/kubecfg01.conf"
             - "/live/cfg/kubecfg/kubecfg02.conf"
             - "/live/cfg/kubecfg/kubecfg03.conf"
       ipvs:
         ips: [ "2004::192:168:143:192","2004::192:168:138:100","2004::192:168:129:100" ]
         ports:
           - port: 80
             virtual_server_config: |
               delay_loop 10
               lb_algo rr
               lb_kind NAT
               protocol TCP
             raw_check: |
               TCP_CHECK {
                   connect_timeout 1
                   connect_port 1936
               }
   ```

6. Выполните следующую команду в бизнес-кластере, чтобы проверить дату истечения сертификата в конфигурационном файле, убедившись, что сертификат все еще действителен. Функциональность LB станет недоступной после истечения срока действия сертификата, требуя обращения к администратору платформы для обновления сертификата.

   ```
   openssl x509 -in <(cat /etc/kubernetes/admin.conf | grep client-certificate-data | awk '{print $NF}' | base64 -d ) -noout -dates
   ```

7. Скопируйте файл `/etc/kubernetes/admin.conf` с трех узлов Master в кластере Kubernetes в папку `/etc/keepalived/kubecfg` на узлах внешнего LB, называя их с индексом, например, `kubecfg01.conf`, и измените адреса узлов `apiserver` в этих трех файлах на фактические адреса узлов кластера Kubernetes.

   **Примечание**: После обновления сертификата платформы этот шаг следует выполнить снова, перезаписав оригинальные файлы.

8. Проверьте действительность сертификатов.

   1. Скопируйте `/usr/bin/kubectl` с узла Master бизнес-кластера на узел LB.

   2. Выполните `chmod +x /usr/bin/kubectl`, чтобы предоставить права на выполнение.

   3. Выполните следующие команды, чтобы подтвердить действительность сертификата.

      ```
      kubectl --kubeconfig=/etc/keepalived/kubecfg/kubecfg01.conf get node
      kubectl --kubeconfig=/etc/keepalived/kubecfg/kubecfg02.conf get node
      kubectl --kubeconfig=/etc/keepalived/kubecfg/kubecfg03.conf get node
      ```

      Если вернутся следующие результаты, сертификат действителен.

      ```
      kubectl --kubeconfig=/etc/keepalived/kubecfg/kubecfg01.conf get node
      ## Вывод
      NAME              STATUS   ROLES                  AGE     VERSION
      192.168.129.100   Ready    <none>                 7d22h   v1.25.6
      192.168.134.167   Ready    control-plane,master   7d22h   v1.25.6
      192.168.138.100   Ready    <none>                 7d22h   v1.25.6
      192.168.143.116   Ready    control-plane,master   7d22h   v1.25.6
      192.168.143.192   Ready    <none>                 7d22h   v1.25.6
      192.168.143.79    Ready    control-plane,master   7d22h   v1.25.6

      kubectl --kubeconfig=/etc/keepalived/kubecfg/kubecfg02.conf get node
      ## Вывод
      NAME              STATUS   ROLES                  AGE     VERSION
      192.168.129.100   Ready    <none>                 7d22h   v1.25.6
      192.168.134.167   Ready    control-plane,master   7d22h   v1.25.6
      192.168.138.100   Ready    <none>                 7d22h   v1.25.6
      192.168.143.116   Ready    control-plane,master   7d22h   v1.25.6
      192.168.143.192   Ready    <none>                 7d22h   v1.25.6
      192.168.143.79    Ready    control-plane,master   7d22h   v1.25.6

      kubectl --kubeconfig=/etc/keepalived/kubecfg/kubecfg03.conf get node
      ## Вывод
      NAME              STATUS   ROLES                  AGE     VERSION
      192.168.129.100   Ready    <none>                 7d22h   v1.25.6
      192.168.134.167   Ready    control-plane,master   7d22h   v1.25.6
      192.168.138.100   Ready    <none>                 7d22h   v1.25.6
      192.168.143.116   Ready    control-plane,master   7d22h   v1.25.6
      192.168.143.192   Ready    <none>                 7d22h   v1.25.6
      192.168.143.79    Ready    control-plane,master   7d22h   v1.25.6
      ```

9. Загрузите образ Keepalived на узел внешнего LB и запустите Keepalived с помощью Docker.

   ```
   docker run -dt --restart=always --privileged --network=host -v /etc/keepalived:/live/cfg build-harbor.alauda.cn/tkestack/keepalived:v3.16.0-beta.3.g598ce923
   ```

10. Выполните следующую команду на узле, обращающемся к `keepalived`: `sysctl -w net.ipv4.conf.all.arp_accept=1`.

## Проверка

1. Выполните команду `ipvsadm -ln`, чтобы просмотреть правила IPVS, и вы увидите правила IPv4 и IPv6, применимые к ALB бизнес-кластера.

   ```
   IP Virtual Server version 1.2.1 (size=4096)
   Prot LocalAddress:Port Scheduler Flags
     -> RemoteAddress:Port           Forward Weight        ActiveConn InActConn
   TCP  192.168.128.118:80 rr
     -> 192.168.129.100:80           Masq    1      0          0        
     -> 192.168.138.100:80           Masq    1      0          0        
     -> 192.168.143.192:80           Masq    1      0          0        
   TCP  [2004::192:168:128:118]:80 rr
     -> [2004::192:168:129:100]:80   Masq    1      0          0        
     -> [2004::192:168:138:100]:80   Masq    1      0          0        
     -> [2004::192:168:143:192]:80   Masq    1      0          0
   ```

2. Выключите узел LB, на котором находится VIP, и проверьте, может ли VIP как IPv4, так и IPv6 успешно мигрировать на другой узел, обычно в течение 20 секунд.

3. Используйте команду `curl` на узле, не являющемся LB, чтобы проверить, нормально ли осуществляется связь с VIP.

   ```
   curl 192.168.128.118

   <!DOCTYPE html>
   <html>
   <head>
   <title>Добро пожаловать в nginx!</title>
   <style>
   html { color-scheme: light dark; }
   body { width: 35em; margin: 0 auto;
   font-family: Tahoma, Verdana, Arial, sans-serif; }
   </style>
   </head>
   <body>
   <h1>Добро пожаловать в nginx!</h1>
   <p>Если вы видите эту страницу, веб-сервер nginx успешно установлен и работает. Требуется дальнейшая настройка.</p>

   <p>Для онлайн-документации и поддержки, пожалуйста, обратитесь к <a href="http://nginx.org/">nginx.org</a>.<br/>
   Коммерческая поддержка доступна на <a href="http://nginx.com/">nginx.com</a>.</p>

   <p><em>Спасибо за использование nginx.</em></p>
   </body>
   </html>
   ```

   ```
   curl -6 [2004::192:168:128:118]:80 -g

   <!DOCTYPE html>
   <html>
   <head>
   <title>Добро пожаловать в nginx!</title>
   <style>
   html { color-scheme: light dark; }
   body { width: 35em; margin: 0 auto;
   font-family: Tahoma, Verdana, Arial, sans-serif; }
   </style>
   </head>
   <body>
   <h1>Добро пожаловать в nginx!</h1>
   <p>Если вы видите эту страницу, веб-сервер nginx успешно установлен и работает. Требуется дальнейшая настройка.</p>

   <p>Для онлайн-документации и поддержки, пожалуйста, обратитесь к <a href="http://nginx.org/">nginx.org</a>.<br/>
   Коммерческая поддержка доступна на<a href="http://nginx.com/">nginx.com</a>.</p>

   <p><em>Спасибо за использование nginx.</em></p>
   </body>
   </html>
   ```
