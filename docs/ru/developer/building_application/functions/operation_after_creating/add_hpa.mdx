---
weight: 20
sourceSHA: cb1bc83d75a4d7c58091eddcb4644810fef6b574f854883cb6424a5010e15fab
---

# Настройка HPA

HPA (Horizontal Pod Autoscaler) автоматически регулирует количество подов вверх или вниз в зависимости от заранее заданных политик и метрик, позволяя приложениям справляться с внезапными всплесками нагрузки, одновременно оптимизируя использование ресурсов в периоды низкой нагрузки.

## Понимание горизонтальных автоскейлеров подов

Вы можете создать горизонтальный автоскейлер подов, чтобы указать минимальное и максимальное количество подов, которые вы хотите запустить, а также целевое использование CPU или памяти для ваших подов.

После создания горизонтального автоскейлера подов платформа начинает запрашивать метрики ресурсов CPU и/или памяти на подах. Когда эти метрики становятся доступными, горизонтальный автоскейлер подов вычисляет соотношение текущего использования метрики к желаемому использованию метрики и соответственно увеличивает или уменьшает количество подов. Запрос и масштабирование происходят через регулярные интервалы, но может потребоваться от одной до двух минут, прежде чем метрики станут доступными.

Для контроллеров репликации это масштабирование напрямую соответствует репликам контроллера репликации. Для конфигураций развертывания масштабирование напрямую соответствует количеству реплик конфигурации развертывания. Обратите внимание, что автоскейлинг применяется только к последнему развертыванию в фазе Завершено.

Платформа автоматически учитывает ресурсы и предотвращает ненужное автоскейлинг во время всплесков ресурсов, таких как при запуске. Подов в состоянии "не готов" имеют 0% использования CPU при увеличении и автоскейлер игнорирует поды при уменьшении. Подов без известных метрик имеют 0% использования CPU при увеличении и 100% CPU при уменьшении. Это обеспечивает большую стабильность во время принятия решений HPA. Чтобы использовать эту функцию, вы должны настроить проверки готовности, чтобы определить, готов ли новый под к использованию.

### Как работает HPA?

Горизонтальный автоскейлер подов (HPA) расширяет концепцию автоскейлинга подов. HPA позволяет вам создавать и управлять группой узлов с балансировкой нагрузки. HPA автоматически увеличивает или уменьшает количество подов, когда превышается заданный порог использования CPU или памяти.

HPA работает как контрольный цикл с периодом синхронизации по умолчанию 15 секунд. В течение этого периода менеджер контроллера запрашивает использование CPU, памяти или обоих, в соответствии с тем, что определено в конфигурации для HPA. Менеджер контроллера получает метрики использования из API метрик ресурсов для метрик ресурсов на уровне пода, таких как CPU или память, для каждого пода, на который нацелен HPA.

Если задано целевое значение использования, контроллер вычисляет значение использования как процент от эквивалентного запроса ресурса на контейнерах в каждом поде. Затем контроллер берет среднее значение использования по всем целевым подам и производит соотношение, которое используется для масштабирования желаемого количества реплик.

### Поддерживаемые метрики

Следующие метрики поддерживаются горизонтальными автоскейлерами подов:

| Метрика                       | Описание                                                                                 |
| ------------------------------ | ------------------------------------------------------------------------------------------- |
| **Использование CPU**          | Количество используемых ядер CPU. Может использоваться для расчета процента запрашиваемого CPU пода. |
| **Использование памяти**       | Объем используемой памяти. Может использоваться для расчета процента запрашиваемой памяти пода. |
| **Входящий сетевой трафик**  | Объем сетевого трафика, поступающего в под, измеряемый в KiB/s.                           |
| **Исходящий сетевой трафик** | Объем сетевого трафика, выходящего из пода, измеряемый в KiB/s.                        |
| **Чтение данных из хранилища**     | Объем данных, читаемых из хранилища, измеряемый в KiB/s.                                        |
| **Запись данных в хранилище**    | Объем данных, записываемых в хранилище, измеряемый в KiB/s.                                       |

> **Важно**: Для автоскейлинга на основе памяти использование памяти должно увеличиваться и уменьшаться пропорционально количеству реплик. В среднем:
>
> - Увеличение количества реплик должно приводить к общему уменьшению использования памяти (рабочего набора) на под.
> - Уменьшение количества реплик должно приводить к общему увеличению использования памяти на под.
> - Используйте платформу для проверки поведения памяти вашего приложения и убедитесь, что ваше приложение соответствует этим требованиям перед использованием автоскейлинга на основе памяти.

## Предварительные требования

Пожалуйста, убедитесь, что компоненты мониторинга развернуты в текущем кластере и функционируют должным образом. Вы можете проверить развертывание и состояние здоровья компонентов мониторинга, нажав в правом верхнем углу платформы <span style={{ display: 'inline-flex', alignItems: 'center', gap: '4px', verticalAlign: 'middle' }}><img src="./assets/question.png" alt="expand" style={{ verticalAlign: 'middle' }} /> <span> > **Состояние здоровья платформы**.</span></span>.

## Создание горизонтального автоскейлера подов

### Использование CLI

Вы можете создать горизонтальный автоскейлер подов, используя интерфейс командной строки, определив файл YAML и используя команду `kubectl create`. Следующий пример показывает автоскейлинг для объекта Deployment. Начальное развертывание требует 3 пода. Объект HPA увеличивает минимум до 5. Если использование CPU на подах достигает 75%, количество подов увеличивается до 7:

1. Создайте файл YAML с именем `hpa.yaml` со следующим содержимым:

```yaml
apiVersion: autoscaling/v2 # [!code callout]
kind: HorizontalPodAutoscaler # [!code callout]
metadata:
  name: hpa-demo # [!code callout]
  namespace: default
spec:
  maxReplicas: 7 # [!code callout]
  minReplicas: 3 # [!code callout]
  scaleTargetRef:
    apiVersion: apps/v1 # [!code callout]
    kind: Deployment # [!code callout]
    name: deployment-demo # [!code callout]
  targetCPUUtilizationPercentage: 75 # [!code callout]
```

<Callouts>
  1. Используйте API autoscaling/v2.
  2. Имя ресурса HPA.
  3. Имя развертывания для масштабирования.
  4. Максимальное количество реплик для увеличения.
  5. Минимальное количество реплик для поддержания.
  6. Укажите версию API объекта для масштабирования.
  7. Укажите тип объекта. Объект должен быть Deployment, ReplicaSet или StatefulSet.
  8. Целевой ресурс, к которому применяется HPA.
  9. Целевой процент использования CPU, который запускает масштабирование.
</Callouts>

2. Примените файл YAML для создания HPA:

```bash
$ kubectl create -f hpa.yaml
```

Пример вывода:

```
horizontalpodautoscaler.autoscaling/hpa-demo created
```

3. После создания HPA вы можете просмотреть новое состояние развертывания, выполнив следующую команду:

```bash
$ kubectl get deployment deployment-demo
```

Пример вывода:

```
NAME              READY   UP-TO-DATE   AVAILABLE   AGE
deployment-demo   5/5     5            5           3m
```

4. Вы также можете проверить статус вашего HPA:

```bash
$ kubectl get hpa hpa-demo
```

Пример вывода:

```
NAME         REFERENCE                  TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
hpa-demo   Deployment/deployment-demo   0%/75%     3         7         3          2m
```

### Использование веб-консоли

1. Войдите в **Контейнерную платформу**.

2. В левой навигационной панели нажмите **Рабочие нагрузки** > **Развертывания**.

3. Щелкните на ***Имя развертывания***.

4. Прокрутите вниз до области **Эластичное масштабирование** и нажмите **Обновить** справа.

5. Выберите **Горизонтальное масштабирование** и завершите настройку политики.

   | Параметр                      | Описание                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
   | ------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
   | **Количество подов**                  | После успешного создания развертывания вам необходимо оценить **Минимальное количество подов**, соответствующее известным и регулярным изменениям бизнес-объема, а также **Максимальное количество подов**, которое может быть поддержано квотой пространства имен при высокой нагрузке. Максимальные или минимальные количества подов могут быть изменены после установки, и рекомендуется сначала получить более точное значение через тестирование производительности и непрерывно корректировать в процессе использования, чтобы соответствовать бизнес-требованиям.                                                                                         |
   | **Политика триггера**             | Список **Метрик**, которые чувствительны к изменениям в бизнесе, и их **Целевые пороги** для запуска действий по увеличению или уменьшению масштаба. <br /> Например, если вы установите *Использование CPU = 60%*, как только использование CPU отклонится от 60%, платформа начнет автоматически корректировать количество подов на основе недостаточного или избыточного распределения ресурсов текущего развертывания. <br /> **Примечание**: Типы метрик включают встроенные метрики и пользовательские метрики. Пользовательские метрики применяются только к развертываниям в нативных приложениях, и вы должны сначала [добавить пользовательские метрики]() . |
   | **Шаг увеличения/уменьшения (Alpha)** | Для бизнеса с конкретными требованиями к скорости масштабирования вы можете постепенно адаптироваться к изменениям в бизнес-объеме, указав **Шаг увеличения** или **Шаг уменьшения**. <br /> Для шага уменьшения вы можете настроить **Окно стабильности**, которое по умолчанию составляет 300 секунд, что означает, что необходимо подождать 300 секунд перед выполнением действий по уменьшению масштаба.                                                                                                                                                                                                                           |

6. Нажмите **Обновить**.

### Использование пользовательских метрик для HPA

Пользовательские метрики HPA расширяют оригинальный HorizontalPodAutoscaler, поддерживая дополнительные метрики помимо использования CPU и памяти.

#### Требования

- kube-controller-manager: horizontal-pod-autoscaler-use-rest-clients=true
- Предварительно установленный metrics-server
- Prometheus
- custom-metrics-api

#### Традиционный (основные метрики) HPA

Традиционный HPA поддерживает метрики использования CPU и памяти для динамической настройки количества экземпляров подов, как показано в следующем примере:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-app-nginx
  namespace: test-namespace
spec:
  maxReplicas: 1
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-app-nginx
  targetCPUUtilizationPercentage: 50
```

В этом YAML `scaleTargetRef` указывает на объект нагрузки для масштабирования, а `targetCPUUtilizationPercentage` указывает на триггер метрики использования CPU.

#### Пользовательские метрики HPA

Чтобы использовать пользовательские метрики, вам необходимо установить prometheus-operator и custom-metrics-api. После установки custom-metrics-api предоставляет большое количество ресурсов пользовательских метрик:

```json
{
  "kind": "APIResourceList",
  "apiVersion": "v1",
  "groupVersion": "custom.metrics.k8s.io/v1beta1",
  "resources": [
    {
      "name": "namespaces/go_memstats_heap_sys_bytes",
      "singularName": "",
      "namespaced": false,
      "kind": "MetricValueList",
      "verbs": ["get"]
    },
    {
      "name": "jobs.batch/go_memstats_last_gc_time_seconds",
      "singularName": "",
      "namespaced": true,
      "kind": "MetricValueList",
      "verbs": ["get"]
    },
    {
      "name": "pods/go_memstats_frees",
      "singularName": "",
      "namespaced": true,
      "kind": "MetricValueList",
      "verbs": ["get"]
    }
  ]
}
```

Эти ресурсы являются подресурсами под MetricValueList. Вы можете создавать правила через Prometheus для создания или поддержания подресурсов. Формат YAML HPA для пользовательских метрик отличается от традиционного HPA:

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: demo
spec:
  scaleTargetRef:
    apiVersion: extensions/v1beta1
    kind: Deployment
    name: demo
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Pods
      pods:
        metricName: metric-demo
        targetAverageValue: 10
```

В этом примере `scaleTargetRef` указывает на нагрузку.

#### Определение условий триггера

- `metrics` является массивом, поддерживающим несколько метрик
- `metric type` может быть: Object (описание ресурсов k8s), Pods (описание метрик для каждого пода), Resources (встроенные метрики k8s: CPU, память) или External (обычно метрики, внешние для кластера)
- Если пользовательская метрика не предоставляется Prometheus, вам необходимо создать новую метрику через ряд операций, таких таких как создание правил в Prometheus

Основная структура метрики выглядит следующим образом:

```json
{
      "describedObject": {  # Описанный объект (Pod)
        "kind": "Pod",
        "namespace": "monitoring",
        "name": "nginx-788f78d959-fd6n9",
        "apiVersion": "/v1"
      },
      "metricName": "metric-demo",
      "timestamp": "2020-02-5T04:26:01Z",
      "value": "50"
}
```

Эти данные метрики собираются и обновляются Prometheus.

#### Совместимость пользовательских метрик HPA

YAML пользовательских метрик HPA на самом деле совместим с оригинальными основными метриками (CPU). Вот как это написать:

```yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: nginx
spec:
  scaleTargetRef:
    apiVersion: extensions/v1beta1
    kind: Deployment
    name: nginx
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 80
    - type: Resource
      resource:
        name: memory
        targetAverageValue: 200Mi
```

- `targetAverageValue` — это среднее значение, полученное для каждого пода
- `targetAverageUtilization` — это использование, рассчитанное из прямого значения

Ссылка на алгоритм:

```
replicas = ceil(sum(CurrentPodsCPUUtilization) / Target)
```

#### Обновления в autoscaling/v2beta2

autoscaling/v2beta2 поддерживает использование памяти:

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx
  namespace: default
spec:
  minReplicas: 1
  maxReplicas: 3
  metrics:
    - resource:
        name: cpu
        target:
          averageUtilization: 70
          type: Utilization
      type: Resource
    - resource:
        name: memory
        target:
          averageUtilization:
          type: Utilization
      type: Resource
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx
```

Изменения: `targetAverageUtilization` и `targetAverageValue` были изменены на `target` и преобразованы в комбинацию `xxxValue` и `type`:

- `xxxValue`: AverageValue (среднее значение), AverageUtilization (среднее использование), Value (прямое значение)
- `type`: Utilization (использование), AverageValue (среднее значение)

**Примечания**:

- Для метрик **Использование CPU** и **Использование памяти** автоскейлинг будет запускаться только тогда, когда фактическое значение колеблется за пределами диапазона ±10% целевого порога.

- Уменьшение масштаба может повлиять на текущие бизнес-операции; пожалуйста, действуйте с осторожностью.

## Правила расчета

Когда бизнес-метрики изменяются, платформа автоматически рассчитывает целевое количество подов, соответствующее бизнес-объему, согласно следующим правилам, и корректирует его соответственно. Если бизнес-метрики продолжают колебаться, значение будет скорректировано до установленного **Минимального количества подов** или **Максимального количества подов**.

- Целевое количество подов для одиночной политики: ceil\[(sum(фактические значения метрики)/порог метрики)] . Это означает, что сумма фактических значений метрики всех подов делится на порог метрики, округляется вверх до наименьшего целого числа, которое больше или равно результату. Например: Если в настоящее время есть 3 пода с использованием ЦП 80%, 80% и 90%, и установленный порог использования ЦП составляет 60%. Согласно формуле количество подов будет автоматически скорректировано до: ceil\[(80%+80%+90%)/60%] = ceil 4.1 = 5 подов.

  **Примечание**:

  - Если рассчитанное целевое количество подов превышает установленное **Максимальное количество подов** (например, *4*), платформа увеличит количество подов только до 4. Если после изменения максимального количества подов метрики продолжают оставаться высокими, возможно, вам потребуется использовать альтернативные методы масштабирования, такие как увеличение квоты подов пространства имен или добавление аппаратных ресурсов.

  - Если рассчитанное целевое количество подов (в предыдущем примере *5*) меньше количества подов, скорректированного в соответствии с **Шагом увеличения** (например, *10*), платформа увеличит количество подов только до 5.

- Целевое количество подов для нескольких политик: выбрать максимальное значение среди результатов каждого расчета политики.
