---
weight: 30
sourceSHA: 6e1c10cec40ff7069ebd8e5078cb9247b54a981063afa3352c822366ac9bf0e0
---

# Концепции

## Компоненты с открытым исходным кодом

### Filebeat

**Позиционирование**: Легковесный сборщик логов  
**Описание**: Компонент для сбора логов с открытым исходным кодом, установленный на узлах контейнеров, отвечающий за мониторинг файлов логов в реальном времени по указанным путям. Он собирает логовые данные через входные модули, обрабатывает их и передает логи в Kafka или напрямую доставляет их в компоненты хранения через выходные модули. Он поддерживает функции, такие как агрегация многоточных логов и фильтрация полей для предварительной обработки.

### Elasticsearch

**Позиционирование**: Распределённый поисковый и аналитический движок  
**Описание**: Движок полнотекстового поиска на основе Lucene, хранящий логовые данные в формате JSON-документов и обеспечивающий возможности поиска почти в реальном времени. Он поддерживает динамическое сопоставление для автоматического распознавания типов полей и достигает быстрого поиска по ключевым словам с помощью обратной индексации, что делает его подходящим для поиска логов и мониторинга предупреждений.

### ClickHouse

**Позиционирование**: Колонковая аналитическая база данных  
**Описание**: Высокопроизводительная колонковая база данных, предназначенная для OLAP-сценариев, реализующая хранение логовых данных на уровне PB с помощью движка MergeTree. Он поддерживает высокоскоростные агрегирующие запросы, временное разбиение и стратегии TTL для данных, что делает его подходящим для анализа логов и статистической отчетности в сценариях пакетной обработки.

### Kafka

**Позиционирование**: Распределённая очередь сообщений  
**Описание**: Является промежуточным программным обеспечением для обмена сообщениями в системе логового потока, предоставляя возможности буферизации логов с высоким пропуском. Когда кластер Elasticsearch испытывает узкие места в обработке, он получает данные логов, отправленные Filebeat через Topics, способствуя снижению пикового трафика и асинхронному потреблению, обеспечивая стабильность на конце сбора логов.

## Концепции основной функциональности

### Поток сбора логов

**Описание**: Полная цепочка от генерации логовых данных до хранения, состоящая из четырех этапов: `Сбор -> Передача -> Буферизация -> Хранение`. Поддерживает два режима потока:

- **Режим прямой записи**: Filebeat → Elasticsearch/ClickHouse
- **Буферный режим**: Filebeat → Kafka → Elasticsearch

### Индекс

**Описание**: Логическая единица разбиения данных в Elasticsearch, аналогичная структуре таблицы в базах данных. Поддерживает создание временных индексов (например, logstash-2023.10.01) и автоматизированное горячее-теплое-холодное управляемое хранение через управление жизненным циклом индекса (ILM).

### Шарды и реплики

**Описание**:

- **Шард**: Физическая единица хранения, получаемая в результате горизонтального разделения индекса в Elasticsearch, поддерживающая распределенную масштабируемость.
- **Реплика**: Копия каждого шарда, обеспечивающая высокую доступность данных и балансировку нагрузки при запросах.

### Колонковое хранение

**Описание**: Основной механизм хранения в ClickHouse, где данные сжимаются и хранятся по колонкам, значительно уменьшая потребление I/O. Поддерживает следующие функции:

- Векторизированный движок выполнения запросов
- Разбиение и шардинг данных
- Материализованные представления для предварительной агрегации

## Ключевые технические термины

### Поток обработки данных

**Описание**: Поток предварительной обработки данных в Elasticsearch, способный выполнять операции ETL, такие как переименование полей, анализ Grok и условная логика перед записью данных.

### Группа потребителей

**Описание**: Механизм параллельного потребления Kafka, где несколько экземпляров в одной группе потребителей могут параллельно получать сообщения из разных разделов, обеспечивая упорядоченную обработку сообщений.

### TTL (Время жизни)

**Описание**: Стратегия жизнеспособности данных, поддерживающая два метода реализации:

- Elasticsearch: Автоматически удаляет устаревшие индексы через политики ILM.
- ClickHouse: Автоматически удаляет разделы таблицы через выражения TTL.

### Фактор репликации

**Описание**: Конфигурация избыточности данных на уровне темы Kafka, определяющая количество реплик сообщений на разных брокерах, повышая надежность данных.

## Модель потока данных

```mermaid
graph LR
    A[Лог-файлы контейнеров] --> B[Агент Filebeat]
    B -->|Режим прямой записи| C{Компонент хранения}
    B -->|Буферный режим| D[Кластер Kafka]
    D --> E[Потребитель Elasticsearch]
    E --> C
    C -->|Elasticsearch| F[Интерфейс индекса/поиска]
    C -->|ClickHouse| G[Интерфейс SQL-запросов]
```
