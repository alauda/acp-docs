---
weight: 10
sourceSHA: b5e50c9e15e16ae9d7eaea68694c5ba0ba84972dfb285abf07534ab0051c28b3
---

# Как архивировать логи в стороннее хранилище

В настоящее время логи, создаваемые платформой, будут храниться в компоненте хранения логов; однако срок хранения этих логов относительно короток. Для предприятий с высокими требованиями к соблюдению норм логам обычно требуется более длительное время хранения для удовлетворения требований аудита. Кроме того, экономический аспект хранения также является одним из ключевых вопросов для предприятий.

Основываясь на вышеизложенных сценариях, платформа предлагает решение по архивированию логов, позволяющее пользователям передавать логи во внешние NFS или объектное хранилище.

## Передача в внешнее NFS

### Предварительные условия

| Ресурс           | Описание                                                                                                                                                                                                                                                                                                                                                                                           |
| ---------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **NFS**          | Заранее настройте службу NFS и определите путь NFS, который будет смонтирован.                                                                                                                                                                                                                                                                                                                   |
| **Kafka**        | Заранее получите адрес службы Kafka.                                                                                                                                                                                                                                                                                                                                                              |
| **Адрес изображения** | Вы должны использовать инструмент CLI в кластере `global`, чтобы выполнить следующие команды для получения адресов изображений:<br />- Получить адрес изображения alpine: `kubectl get daemonset nevermore -n cpaas-system -o jsonpath='{.spec.template.spec.initContainers[0].image}'` <br />- Получить адрес изображения razor: `kubectl get deployment razor -n cpaas-system -o jsonpath='{.spec.template.spec.containers[0].image}'` |

### Создание ресурсов синхронизации логов

1. Нажмите на **Управление кластерами** > **Кластеры** в левой боковой панели.

2. Нажмите на кнопку действия справа от кластера, в который будут передаваться логи > **Инструмент CLI**.

3. Измените YAML на основе следующих описаний параметров; после изменения вставьте код в открытый командный интерфейс **CLI Tool** и нажмите Enter для выполнения.

   | Тип ресурса | Поле | Описание                                                                                                                                                               |
   | ------------ | ----- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
   | ConfigMap    | `data.export.yml.output.compression`          | Сжать текст логов; поддерживаемые варианты: **none (без сжатия)**, **zlib**, **gzip**.                                                                                  |
   | ConfigMap    | `data.export.yml.output.file_type`            | Тип экспортируемого файла логов; поддерживает txt, csv, json.                                                                                                            |
   | ConfigMap    | `data.export.yml.output.max_size`             | Размер одного архивированного файла; единица измерения - MB. Если он превышает это значение, логи будут автоматически сжаты и архивированы в соответствии с конфигурацией поля сжатия. |
   | ConfigMap    | `data.export.yml.scopes`                      | Область передачи логов; в настоящее время поддерживаются следующие логи: системные логи, логи приложений, логи Kubernetes, продуктовые логи.                               |
   | Deployment    | `spec.template.spec.containers[0].command[7]` | Адрес службы Kafka.                                                                                                                                                      |
   | Deployment    | `spec.template.spec.volumes[3].hostPath.path` | Путь NFS, который необходимо смонтировать.                                                                                                                                 |
   | Deployment    | `spec.template.spec.initContainers[0].image`  | Адрес изображения Alpine.                                                                                                                                                 |
   | Deployment    | `spec.template.spec.containers[0].image`      | Адрес изображения Razor.                                                                                                                                                  |

   ```yaml
   cat << "EOF" |kubectl apply -f -
   apiVersion: v1
   data:
     export.yml: |
       scopes: # Область передачи логов; по умолчанию собираются только логи приложений
         system: false  # Системные логи
         workload: true # Логи приложений
         kubernetes: false # Логи Kubernetes
         platform: false # Продуктовые логи
       output:
         type: local                              
         path: /cpaas/data/logarchive           
         layout: TimePrefixed
         # Размер одного архивированного файла; единица измерения - MB. Если он превышает это значение, логи будут автоматически сжаты и архивированы в соответствии с конфигурацией поля сжатия.
         max_size: 200         
         compression: zlib    # Необязательно: none (без сжатия) / zlib / gzip
         file_type: txt   # Необязательно: txt csv json
   kind: ConfigMap
   metadata:
     name: log-exporter-config
     namespace: cpaas-system
    
   ---
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     labels:
       service_name: log-exporter
     name: log-exporter
     namespace: cpaas-system
   spec:
     progressDeadlineSeconds: 600
     replicas: 1
     revisionHistoryLimit: 5
     selector:
       matchLabels:
         service_name: log-exporter
     strategy:
       rollingUpdate:
         maxSurge: 0
         maxUnavailable: 1
       type: RollingUpdate
     template:
       metadata:
         creationTimestamp: null
         labels:
           app: lanaya
           cpaas.io/product: Platform-Center
           service_name: log-exporter
           version: v1
         namespace: cpaas-system
       spec:
         affinity:
           podAffinity: {}
           podAntiAffinity:
             preferredDuringSchedulingIgnoredDuringExecution:
               - podAffinityTerm:
                   labelSelector:
                     matchExpressions:
                       - key: service_name
                         operator: In
                         values:
                           - log-exporter
                   topologyKey: kubernetes.io/hostname
                 weight: 50
         initContainers:
           - args:
               - -ecx
               - |
                 chown -R 697:697 /cpaas/data/logarchive
             command:
               - /bin/sh
             image: registry.example.cn:60080/ops/alpine:3.16 # Адрес изображения Alpine
             imagePullPolicy: IfNotPresent
             name: chown
             resources:
               limits:
                 cpu: 100m
                 memory: 200Mi
               requests:
                 cpu: 10m
                 memory: 50Mi
             securityContext:
               runAsUser: 0
             terminationMessagePath: /dev/termination-log
             terminationMessagePolicy: File
             volumeMounts:
               - mountPath: /cpaas/data/logarchive
                 name: data
         containers:
           - command:
             - /razor
             - consumer
             - --v=1
             - --kafka-group-log=log-nfs
             - --kafka-auth-enabled=true
             - --kafka-tls-enabled=true
             - --kafka-endpoint=192.168.143.120:9092  # Заполните в соответствии с фактической средой
             - --database-type=file
             - --export-config=/etc/log-export/export.yml
             image: registry.example.cn:60080/ait/razor:v3.16.0-beta.3.g3df8e987  # Изображение Razor
             imagePullPolicy: Always
             livenessProbe:
               failureThreshold: 5
               httpGet:
                 path: /metrics
                 port: 8080
                 scheme: HTTP
               initialDelaySeconds: 20
               periodSeconds: 10
               successThreshold: 1
               timeoutSeconds: 3
             name: log-export
             ports:
               - containerPort: 80
                 protocol: TCP
             readinessProbe:
               failureThreshold: 5
               httpGet:
                 path: /metrics
                 port: 8080
                 scheme: HTTP
               initialDelaySeconds: 20
               periodSeconds: 10
               successThreshold: 1
               timeoutSeconds: 3
             resources:
               limits:
                 cpu: "2"
                 memory: 4Gi
               requests:
                 cpu: 440m
                 memory: 1280Mi
             securityContext:
               runAsGroup: 697
               runAsUser: 697
             terminationMessagePath: /dev/termination-log
             terminationMessagePolicy: File
             volumeMounts:
               - mountPath: /etc/secrets/kafka
                 name: kafka-basic-auth
                 readOnly: true
               - mountPath: /etc/log-export
                 name: config
                 readOnly: true
               - mountPath: /cpaas/data/logarchive 
                 name: data
         dnsPolicy: ClusterFirst
         nodeSelector:
           kubernetes.io/os: linux
         restartPolicy: Always
         schedulerName: default-scheduler
         securityContext:
           fsGroup: 697
         serviceAccount: lanaya
         serviceAccountName: lanaya
         terminationGracePeriodSeconds: 10
         tolerations:
           - effect: NoSchedule
             key: node-role.kubernetes.io/master
             operator: Exists
           - effect: NoSchedule
             key: node-role.kubernetes.io/control-plane
             operator: Exists
           - effect: NoSchedule
             key: node-role.kubernetes.io/cpaas-system
             operator: Exists
         volumes:
           - name: kafka-basic-auth
             secret:
               defaultMode: 420
               secretName: kafka-basic-auth
           - name: elasticsearch-basic-auth
             secret:
               defaultMode: 420
               secretName: elasticsearch-basic-auth
           - configMap:
               defaultMode: 420
               name: log-exporter-config
             name: config
           - hostPath:
               path: /cpaas/data/logarchive    # Путь NFS для монтирования
               type: DirectoryOrCreate
             name: data
   EOF
   ```

4. После изменения статуса контейнера на Running вы можете просмотреть непрерывно архивируемые логи по пути NFS; структура директорий файлов логов выглядит следующим образом:

   ```bash
   /cpaas/data/logarchive/$date/$project/$namespace-$cluster/logfile
   ```

## Передача во внешнее хранилище S3

### Предварительные условия

| Ресурс           | Описание                                                                                                                                                                                                                                                                                                                                                                                             |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Хранилище S3** | Заранее подготовьте адрес службы хранения S3 и получите значения для `access_key_id` и `secret_access_key`; создайте корзину, в которую будут сохраняться логи.                                                                                                                                                                                                                                     |
| **Kafka**        | Заранее получите адрес службы Kafka.                                                                                                                                                                                                                                                                                                                                                              |
| **Адрес изображения** | Вы должны использовать инструмент CLI в кластере `global`, чтобы выполнить следующие команды для получения адресов изображений:<br />- Получить адрес изображения alpine: `kubectl get daemonset nevermore -n cpaas-system -o jsonpath='{.spec.template.spec.initContainers[0].image}'` <br />- Получить адрес изображения razor: `kubectl get deployment razor -n cpaas-system -o jsonpath='{.spec.template.spec.containers[0].image}'` |

### Создание ресурсов синхронизации логов

1. Нажмите на **Управление кластерами** > **Кластеры** в левой боковой панели.

2. Нажмите на кнопку действия справа от кластера, в который будут передаваться логи > **Инструмент CLI**.

3. Измените YAML на основе следующих описаний параметров; после изменения вставьте код в открытый командный интерфейс **CLI Tool** и нажмите Enter для выполнения.

   | Тип ресурса | Поле | Описание                                                                                                                                                               |
   | ------------ | ----- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
   | Secret        | `data.access_key_id`                          | Кодируйте в Base64 полученный access\_key\_id.                                                                                                                          |
   | Secret        | `data.secret_access_key`                      | Кодируйте в Base64 полученный secret\_access\_key.                                                                                                                      |
   | ConfigMap    | `data.export.yml.output.compression`          | Сжать текст логов; поддерживаемые варианты: **none (без сжатия)**, **zlib**, **gzip**.                                                                                   |
   | ConfigMap    | `data.export.yml.output.file_type`            | Тип экспортируемого файла логов; поддерживает txt, csv, json.                                                                                                            |
   | ConfigMap    | `data.export.yml.output.max_size`             | Размер одного архивированного файла; единица измерения - MB. Если он превышает это значение, логи будут автоматически сжаты и архивированы в соответствии с конфигурацией поля сжатия. |
   | ConfigMap    | `data.export.yml.scopes`                      | Область передачи логов; в настоящее время поддерживаются следующие логи: системные логи, логи приложений, логи Kubernetes, продуктовые логи.                               |
   | ConfigMap    | `data.export.yml.output.s3.bucket_name`       | Имя корзины.                                                                                                                                                             |
   | ConfigMap    | `data.export.yml.output.s3.endpoint`          | Адрес службы хранения S3.                                                                                                                                               |
   | ConfigMap    | `data.export.yml.output.s3.region`            | Информация о регионе для службы хранения S3.                                                                                                                            |
   | Deployment    | `spec.template.spec.containers[0].command[7]` | Адрес службы Kafka.                                                                                                                                                      |
   | Deployment    | `spec.template.spec.volumes[3].hostPath.path` | Локальный путь для монтирования, используемый для временного хранения информации о логах. Файлы логов будут автоматически удалены после синхронизации в хранилище S3. |
   | Deployment    | `spec.template.spec.initContainers[0].image`  | Адрес изображения Alpine.                                                                                                                                                 |
   | Deployment    | `spec.template.spec.containers[0].image`      | Адрес изображения Razor.                                                                                                                                                  |

   ```yaml
   cat << "EOF" |kubectl apply -f -
   apiVersion: v1
   type: Opaque
   data:
     # Должны содержать следующие два ключа
     access_key_id: bWluaW9hZG1pbg==  # Кодируйте в Base64 полученный access_key_id
     secret_access_key: bWluaW9hZG1pbg==  # Кодируйте в Base64 полученный secret_access_key
   kind: Secret
   metadata:
     name: log-export-s3-secret
     namespace: cpaas-system
     
   ---
   apiVersion: v1
   data:
     export.yml: |
       scopes: # Область передачи логов; по умолчанию собираются только логи приложений
         system: false  # Системные логи
         workload: true # Логи приложений
         kubernetes: false # Логи Kubernetes
         platform: false # Продуктовые логи
       output:
         type: s3                             
         path: /cpaas/data/logarchive             
         
         s3:
           s3forcepathstyle: true
           bucket_name: baucket_name_s3           # Заполните подготовленным именем корзины
           endpoint: http://192.168.179.86:9000   # Заполните адресом службы хранения S3
           region: "dummy"                        # Информация о регионе
           access_secret: log-export-s3-secret    
           insecure: true
                               
         layout: TimePrefixed
         # Размер одного архивированного файла; единица измерения - MB. Если он превышает это значение, логи будут автоматически сжаты и архивированы в соответствии с конфигурацией поля сжатия.
         max_size: 200                            
         compression: zlib                        # Необязательно: none (без сжатия) / zlib / gzip
         file_type: txt                           # Необязательно: txt, csv, json
   kind: ConfigMap
   metadata:
     name: log-exporter-config
     namespace: cpaas-system
    
   ---
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     labels:
       service_name: log-exporter
     name: log-exporter
     namespace: cpaas-system
   spec:
     progressDeadlineSeconds: 600
     replicas: 1
     revisionHistoryLimit: 5
     selector:
       matchLabels:
         service_name: log-exporter
     strategy:
       rollingUpdate:
         maxSurge: 0
         maxUnavailable: 1
       type: RollingUpdate
     template:
       metadata:
         creationTimestamp: null
         labels:
           app: lanaya
           cpaas.io/product: Platform-Center
           service_name: log-exporter
           version: v1
         namespace: cpaas-system
       spec:
         affinity:
           podAffinity: {}
           podAntiAffinity:
             preferredDuringSchedulingIgnoredDuringExecution:
               - podAffinityTerm:
                   labelSelector:
                     matchExpressions:
                       - key: service_name
                         operator: In
                         values:
                           - log-exporter
                   topologyKey: kubernetes.io/hostname
                 weight: 50
         initContainers:
           - args:
               - -ecx
               - |
                 chown -R 697:697 /cpaas/data/logarchive
             command:
               - /bin/sh
             image: registry.example.cn:60080/ops/alpine:3.16 # Адрес изображения Alpine
             imagePullPolicy: IfNotPresent
             name: chown
             resources:
               limits:
                 cpu: 100m
                 memory: 200Mi
               requests:
                 cpu: 10m
                 memory: 50Mi
             securityContext:
               runAsUser: 0
             terminationMessagePath: /dev/termination-log
             terminationMessagePolicy: File
             volumeMounts:
               - mountPath: /cpaas/data/logarchive
                 name: data
         containers:
           - command:
               - /razor
               - consumer
               - --v=1
               - --kafka-group-log=log-s3   
               - --kafka-auth-enabled=true
               - --kafka-tls-enabled=true
               - --kafka-endpoint=192.168.179.86:9092  # Заполните адрес службы Kafka в соответствии с фактической средой
               - --database-type=file
               - --export-config=/etc/log-export/export.yml
             image: registry.example.cn:60080/ait/razor:v3.16.0-beta.3.g3df8e987  # Изображение Razor
             imagePullPolicy: Always
             livenessProbe:
               failureThreshold: 5
               httpGet:
                 path: /metrics
                 port: 8080
                 scheme: HTTP
               initialDelaySeconds: 20
               periodSeconds: 10
               successThreshold: 1
               timeoutSeconds: 3
             name: log-export
             ports:
               - containerPort: 80
                 protocol: TCP
             readinessProbe:
               failureThreshold: 5
               httpGet:
                 path: /metrics
                 port: 8080
                 scheme: HTTP
               initialDelaySeconds: 20
               periodSeconds: 10
               successThreshold: 1
               timeoutSeconds: 3
             resources:
               limits:
                 cpu: "2"
                 memory: 4Gi
               requests:
                 cpu: 440m
                 memory: 1280Mi
             securityContext:
               runAsGroup: 697
               runAsUser: 697
             terminationMessagePath: /dev/termination-log
             terminationMessagePolicy: File
             volumeMounts:
               - mountPath: /etc/secrets/kafka
                 name: kafka-basic-auth
                 readOnly: true
               - mountPath: /etc/log-export
                 name: config
                 readOnly: true
               - mountPath: /cpaas/data/logarchive
                 name: data
         dnsPolicy: ClusterFirst
         nodeSelector:
           kubernetes.io/os: linux
         restartPolicy: Always
         schedulerName: default-scheduler
         securityContext:
           fsGroup: 697
         serviceAccount: lanaya
         serviceAccountName: lanaya
         terminationGracePeriodSeconds: 10
         tolerations:
           - effect: NoSchedule
             key: node-role.kubernetes.io/master
             operator: Exists
           - effect: NoSchedule
             key: node-role.kubernetes.io/control-plane
             operator: Exists
           - effect: NoSchedule
             key: node-role.kubernetes.io/cpaas-system
             operator: Exists
         volumes:
           - name: kafka-basic-auth
             secret:
               defaultMode: 420
               secretName: kafka-basic-auth
           - name: elasticsearch-basic-auth
             secret:
               defaultMode: 420
               secretName: elasticsearch-basic-auth
           - configMap:
               defaultMode: 420
               name: log-exporter-config
             name: config
           - hostPath:
               path: /cpaas/data/logarchive    # Адрес временного хранения логов
               type: DirectoryOrCreate
             name: data
   EOF
   ```

4. После изменения статуса контейнера на Running вы можете просмотреть непрерывно архивируемые логи в корзине.
