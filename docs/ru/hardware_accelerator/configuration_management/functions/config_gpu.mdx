---
weight: 10
sourceSHA: d24caf15a573d79d3681b3f2f53f252b95be53e5be79480ff1711b172d08ec88
---

# Настройка аппаратного ускорителя на узлах GPU

С увеличением объема бизнес-данных, особенно в таких сценариях, как искусственный интеллект и анализ данных, вы можете захотеть использовать возможности GPU в своем собственном бизнес-кластере для ускорения обработки данных. В дополнение к подготовке ресурсов GPU для узлов кластера также необходимо выполнить настройку GPU.

В данном решении узлы кластера с вычислительными возможностями GPU обозначаются как **GPU узлы**.

**Примечание**: Если не указано иное, шаги операции применимы к обоим типам узлов. Для вопросов, связанных с установкой драйвера, смотрите [официальную документацию NVIDIA по установке](https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html).

## Предварительные условия

Ресурсы GPU подготовлены на рабочем узле, который относится к GPU узлу, о котором упоминается в этом разделе.

## <span> Установка драйвера GPU </span>

**Внимание: Если узел GPU использует плагин NVIDIA MPS, убедитесь, что архитектура GPU узла является Volta или новее (Volta/Turing/Ampere/Hopper и т. д.), и драйвер поддерживает версию CUDA 11.5 или выше.**

### Получение адреса для скачивания драйвера

1. Войдите в узел GPU и выполните команду `lspci |grep -i NVIDIA`, чтобы проверить модель GPU узла.

   В следующем примере модель GPU — Tesla T4.

   ```
   lspci | grep NVIDIA
   00:08.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)
   ```

2. Перейдите на [официальный сайт NVIDIA](https://www.nvidia.cn/), чтобы получить ссылку для скачивания драйвера.

   1. Нажмите на **Drivers** в верхней навигационной панели на главной странице.

   2. Заполните необходимые данные для скачивания драйвера в соответствии с моделью узла GPU.

   3. Нажмите на **Search**.

   4. Нажмите на **Download**.

   5. Щелкните правой кнопкой мыши на **Download** > **Copy Link Address**, чтобы скопировать ссылку для скачивания драйвера.

3. Выполните следующие команды на узле GPU для создания каталога `/home/gpu` и загрузки файла драйвера в этот каталог.

   ```
   # Создать каталог /home/gpu
   mkdir -p /home/gpu
   cd /home/gpu/
   # Загрузить файл драйвера в каталог /home/gpu, пример: wget https://cn.download.nvidia.com/tesla/515.65.01/NVIDIA-Linux-x86_64-515.65.01.run
   wget <Адрес для скачивания драйвера>
   # Проверьте, что файл драйвера был успешно загружен. Если возвращается имя файла драйвера (например: NVIDIA-Linux-x86_64-515.65.01.run), это означает, что загрузка была успешной
   ls <Имя файла драйвера>
   ```

### Установка драйвера

1. Выполните следующую команду на узле GPU для установки пакетов gcc и kernel-devel, соответствующих текущей операционной системе.

   ```
   sudo yum install dkms gcc  kernel-devel-$(uname -r) -y
   ```

2. Выполните следующие команды для установки драйвера GPU.

   ```
   chmod a+x /home/gpu/<Имя файла драйвера>
   /home/gpu/<Имя файла драйвера> --dkms
   ```

3. После установки выполните команду `nvidia-smi`. Если возвращается информация о GPU, подобная следующему примеру, это означает, что установка драйвера была успешной.

   ```
   # nvidia-smi
   Tue Sep 13 01:31:33 2022     
   +-----------------------------------------------------------------------------+
   | NVIDIA-SMI 515.65.01    Версия драйвера: 515.65.01    Версия CUDA: 11.7     |
   +-------------------------------+-----------------------+---------------------+
   | GPU  Имя        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
   | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
   |                               |                      |               MIG M. |
   |===============================+======================+======================|
   |   0  Tesla T4            Off  | 00000000:00:08.0 Off |                    0 |
   | N/A   55C    P0    28W /  70W |      2MiB / 15360MiB |      5%      Default |
   |                               |                      |                  N/A |
   +-------------------------------+-----------------------+---------------------+
                                                                                   
   +-----------------------------------------------------------------------------+
   | Процессы:                                                                  |
   |  GPU   GI   CI        PID   Тип   Имя процесса                  Память GPU |
   |        ID   ID                                                   Использование      |
   |=============================================================================|
   |  Запущенных процессов не найдено                                                 |
   +-----------------------------------------------------------------------------+
   ```

### Установка контейнерного времени NVIDIA

1. На **GPU узле** добавьте репозиторий yum NVIDIA.

   ```bash
   distribution=$(. /etc/os-release;echo $ID$VERSION_ID) && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.repo | sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo
   yum makecache -y
   ```

   Когда появляется сообщение "Metadata cache created", это означает, что добавление прошло успешно.

2. Установите NVIDIA Container Runtime.

   ```bash
   yum install nvidia-container-toolkit -y
   ```

   Когда появляется сообщение `Complete!`, это значит, что установка прошла успешно.

3. Настройка времени по умолчанию.
   Добавьте следующую конфигурацию в файл.

   - Containerd: Измените файл `/etc/containerd/config.toml`.

     ```
     [plugins]
      [plugins."io.containerd.grpc.v1.cri"]
        [plugins."io.containerd.grpc.v1.cri".containerd]
     ...
           default_runtime_name = "nvidia"
     ...
             [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
     ...
               [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
                 runtime_type = "io.containerd.runc.v2"
                 runtime_engine = ""
                 runtime_root = ""
                 privileged_without_host_devices = false
                 base_runtime_spec = ""
                 [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
                   SystemdCgroup = true
               [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia]
                 privileged_without_host_devices = false
                 runtime_engine = ""
                 runtime_root = ""
                 runtime_type = "io.containerd.runc.v1"
                 [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options]
                   BinaryName = "/usr/bin/nvidia-container-runtime"
                   SystemdCgroup = true
     ...
     ```

   - Docker: Измените файл `/etc/docker/daemon.json`.
     ```
      {
      ...
          "default-runtime": "nvidia",
          "runtimes": {
          "nvidia": {
              "path": "/usr/bin/nvidia-container-runtime"
              }
          },
      ...
      }
     ```

4. Перезапустите Containerd / Docker.

   - Containerd

     ```
     systemctl restart containerd   #Перезапуск

     crictl info |grep Runtime  #Проверка
     ```

   - Docker

     ```
     systemctl restart docker   #Перезапуск

     docker info |grep Runtime  #Проверка
     ```

## Конфигурация физического GPU

### Развертывание плагина физического GPU в бизнес-кластере GPU

На управленческом интерфейсе кластера GPU выполните следующие действия:

1. В левом боковом меню "Каталог" выберите подменю "Плагины кластера", нажмите, чтобы развернуть "Плагин устройства ACP GPU" и откройте опцию "pGPU";

2. На вкладке "Узлы" выберите узлы, которым необходимо развернуть физический GPU, затем нажмите "Менеджер меток и теней", добавьте "метку устройства" и выберите "pGPU", затем нажмите ОК;

3. На вкладке "Pods" проверьте состояние выполнения группы контейнеров, соответствующих nvidia-device-plugin-ds, чтобы увидеть, нет ли отклонений, и убедитесь, что он работает на указанных узлах.

## Конфигурация NVIDIA MPS (поддержка драйвера версия cuda должна быть >= 11.5)

### Развертывание плагина NVIDIA MPS в бизнес-кластере GPU

#### На управленческом интерфейсе кластера GPU выполните следующие действия:

1. В левом боковом меню "Каталог" выберите подменю "Плагины кластера", нажмите, чтобы развернуть "Плагин устройства ACP GPU" и откройте опцию "MPS";

2. На вкладке "Узлы" выберите узлы, которым необходимо развернуть физический GPU, затем нажмите "Менеджер меток и теней", добавьте "метку устройства" и выберите "MPS", затем нажмите ОК;

3. На вкладке "Pods" проверьте состояние выполнения группы контейнеров, соответствующих nvidia-mps-device-plugin-daemonset, чтобы увидеть, нет ли отклонений, и убедитесь, что он работает на указанных узлах.

### Настройка kube-scheduler (kubernetes> = 1.23)

1. На **Управляющем узле бизнес-кластера** проверьте, правильно ли планировщик ссылается на политику планирования.

   ```
   cat /etc/kubernetes/manifests/kube-scheduler.yaml
   ```

   проверьте, есть ли опция –config и значение /etc/kubernetes/scheduler-config.yaml, как в

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     creationTimestamp: null
     labels:
       component: kube-scheduler
      tier: control-plane
     name: kube-scheduler
     namespace: kube-system
   spec:
     containers:
     - command:
       - kube-scheduler
       - --config=/etc/kubernetes/scheduler-config.yaml
   ```

**Примечание**: Вышеуказанные параметры и значения являются значениями по умолчанию платформы. Если вы изменили их, пожалуйста, верните их к значениям по умолчанию. Исходные настраиваемые конфигурации можно скопировать в файл политики планирования.

2. Проверьте конфигурацию файла политики планирования.

   1. Выполните команду: `kubectl describe service kubernetes -n default |grep Endpoints`.

      ```
      Ожидаемый эффект Endpoints:         192.168.130.240:6443
      ```

   2. Замените содержимое файла `/etc/kubernetes/scheduler-config.yaml` на всех узлах Master следующим содержимым, где `${kube-apiserver}` следует заменить на вывод первого шага.

      ```
      apiVersion: kubescheduler.config.k8s.io/v1beta2
      kind: KubeSchedulerConfiguration
      clientConnection:
        kubeconfig: /etc/kubernetes/scheduler.conf
      extenders:
      - enableHTTPS: true
        filterVerb: predicates
        managedResources:
        - ignoredByScheduler: false
          имя: nvidia.com/mps-core
        nodeCacheCapable: false
        urlPrefix: https://${kube-apiserver}/api/v1/namespaces/kube-system/services/nvidia-mps-scheduler-plugin/proxy/scheduler
        tlsConfig:
          insecure: false
          certFile: /etc/kubernetes/pki/apiserver-kubelet-client.crt
          keyFile: /etc/kubernetes/pki/apiserver-kubelet-client.key
          caFile: /etc/kubernetes/pki/ca.crt
      ```

      если schedule-config.yaml уже существует extenders, то добавьте yaml в конец

      ```
      - enableHTTPS: true
        filterVerb: predicates
        managedResources:
        - ignoredByScheduler: false
          имя: nvidia.com/mps-core
        nodeCacheCapable: false
        urlPrefix: https://${kube-apiserver}/api/v1/namespaces/kube-system/services/nvidia-mps-scheduler-plugin/proxy/scheduler
        tlsConfig:
          insecure: false
          certFile: /etc/kubernetes/pki/apiserver-kubelet-client.crt
          keyFile: /etc/kubernetes/pki/apiserver-kubelet-client.key
          caFile: /etc/kubernetes/pki/ca.crt
      ```

3. Запустите следующую команду, чтобы получить идентификатор контейнера:

   - Containerd: Выполните `crictl ps |grep kube-scheduler`, вывод будет следующим, где первый столбец — это идентификатор контейнера.

     ```
     1d113ccf1c1a9       03c72176d0f15       2 секунды назад       Запущен             kube-scheduler              3                   ecd054bbdd465       kube-scheduler-192.168.176.47
     ```

   - Docker: Запустите `docker ps |grep kube-scheduler`, вывод будет следующим, где первый столбец — это идентификатор контейнера.

     ```
     30528a45a118   d8a9fef7349c    "kube-scheduler --au..."   37 минут назад   В работе 37 минут     k8s_kube-scheduler_kube-scheduler-192.168.130.240_kube-system_3e9f7007b38f4deb6ffd1c7587621009_28
     ```

4. Перезапустите контейнер Containerd/Docker, используя полученный на предыдущем шаге идентификатор контейнера.

   - Containerd

     ```
     crictl stop <Идентификатор контейнера>
     ```

5. Перезапустите Kubelet.

   ```
   systemctl restart kubelet
   ```

## Конфигурация GPU-менеджера

### Настройка kube-scheduler (kubernetes> = 1.23)

1. На **Управляющем узле бизнес-кластера** проверьте, правильно ли планировщик ссылается на политику планирования.

   ```
   cat /etc/kubernetes/manifests/kube-scheduler.yaml
   ```

   проверьте, есть ли опция –config и значение /etc/kubernetes/scheduler-config.yaml, как в

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     creationTimestamp: null
     labels:
       component: kube-scheduler
      tier: control-plane
     name: kube-scheduler
     namespace: kube-system
   spec:
     containers:
     - command:
       - kube-scheduler
       - --config=/etc/kubernetes/scheduler-config.yaml
   ```

**Примечание**: Вышеуказанные параметры и значения являются значениями по умолчанию платформы. Если вы изменили их, пожалуйста, верните их к значениям по умолчанию. Исходные настраиваемые конфигурации можно скопировать в файл политики планирования.

2. Проверьте конфигурацию файла политики планирования.

   1. Выполните команду: `kubectl describe service kubernetes -n default |grep Endpoints`.

      ```
      Ожидаемый эффект Endpoints:         192.168.130.240:6443
      ```

   2. Замените содержимое файла `/etc/kubernetes/scheduler-config.yaml` на всех узлах Master следующим содержимым, где `${kube-apiserver}` следует заменить на вывод первого шага.

      ```
      apiVersion: kubescheduler.config.k8s.io/v1beta2
      kind: KubeSchedulerConfiguration
      clientConnection:
        kubeconfig: /etc/kubernetes/scheduler.conf
      extenders:
      - enableHTTPS: true
        filterVerb: predicates
        managedResources:
        - ignoredByScheduler: false
          имя: tencent.com/vcuda-core
        nodeCacheCapable: false
        urlPrefix: https://${kube-apiserver}/api/v1/namespaces/kube-system/services/gpu-quota-admission/proxy/scheduler
        tlsConfig:
          insecure: false
          certFile: /etc/kubernetes/pki/apiserver-kubelet-client.crt
          keyFile: /etc/kubernetes/pki/apiserver-kubelet-client.key
          caFile: /etc/kubernetes/pki/ca.crt
      ```

3. Запустите следующую команду, чтобы получить идентификатор контейнера:

   - Containerd: Выполните `crictl ps |grep kube-scheduler`, вывод будет следующим, где первый столбец — это идентификатор контейнера.

     ```
     1d113ccf1c1a9       03c72176d0f15       2 секунды назад       Запущен             kube-scheduler              3                   ecd054bbdd465       kube-scheduler-192.168.176.47
     ```

   - Docker: Запустите `docker ps |grep kube-scheduler`, вывод будет следующим, где первый столбец — это идентификатор контейнера.

     ```
     30528a45a118   d8a9fef7349c    "kube-scheduler --au..."   37 минут назад   В работе 37 минут     k8s_kube-scheduler_kube-scheduler-192.168.130.240_kube-system_3e9f7007b38f4deb6ffd1c7587621009_28
     ```

4. Перезапустите контейнер Containerd/Docker, используя полученный на предыдущем шаге идентификатор контейнера.

   - Containerd

     ```
     crictl stop <Идентификатор контейнера>
     ```

5. Перезапустите Kubelet.

   ```
   systemctl restart kubelet
   ```

### Развертывание плагина GPU Manager в бизнес-кластере GPU

На управленческом интерфейсе кластера GPU выполните следующие действия:

1. В левом боковом меню "Каталог" выберите подменю "Плагины кластера", нажмите, чтобы развернуть "Плагин устройства ACP GPU" и откройте опцию "GPU-Manager";

2. На вкладке "Узлы" выберите узлы, которым необходимо развернуть физический GPU, затем нажмите "Менеджер меток и теней", добавьте "метку устройства" и выберите "vGPU", затем нажмите ОК;

3. На вкладке "Pods" проверьте состояние выполнения группы контейнеров, соответствующих gpu-manager-daemonset, чтобы увидеть, нет ли отклонений, и убедитесь, что он работает на указанных узлах.

## Проверка результатов

Метод 1: Проверьте, есть ли доступные ресурсы GPU на узлах GPU, выполнив следующую команду на управляющем узле бизнес-кластера:

```
kubectl get node  ${nodeName} -o=jsonpath='{.status.allocatable}' 
```

Метод 2: Разверните приложение GPU на платформе, указав необходимое количество ресурсов GPU. После развертывания выполните exec в Pod и выполните следующую команду:

```
# nvidia-smi
Tue Sep 13 01:31:33 2022     
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Версия драйвера: 515.65.01    Версия CUDA: 11.7     |
+-------------------------------+-----------------------+---------------------+
| GPU  Имя        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:08.0 Off |                    0 |
| N/A   55C    P0    28W /  70W |      2MiB / 15360MiB |      5%      Default |
|                               |                      |                  N/A |
+-------------------------------+-----------------------+---------------------+
                                                                                
+-----------------------------------------------------------------------------+
| Процессы:                                                                  |
|  GPU   GI   CI        PID   Тип   Имя процесса                  Память GPU |
|        ID   ID                                                   Использование      |
|=============================================================================|
|  Запущенных процессов не найдено                                                 |
+-----------------------------------------------------------------------------+
```

Проверьте, была ли получена корректная информация о GPU.
