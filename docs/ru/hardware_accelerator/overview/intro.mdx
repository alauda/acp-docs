---
weight: 10
sourceSHA: 1520c5380271e3635c7b9e6233edd2c9e61e72c3f13a8eed8ed794c565edbf3d
---

# Введение

## Введение в аппаратные акселераторы

Kubernetes Hardware Accelerator Suite — это решение корпоративного уровня для оптимизации распределения ресурсов GPU, их изоляции и совместного использования в облачно-ориентированных средах. Основанное на плагинах устройств Kubernetes и технологиях NVIDIA, оно предоставляет три основные модуля:

1. **Модуль vGPU**\
   Основанный на открытом GPU-менеджере, этот модуль обеспечивает детализированную виртуализацию GPU, разделяя физические GPU на совместно используемые виртуальные единицы с квотами по памяти и вычислениям. Идеально подходит для многопользовательских окружений, требующих динамического распределения ресурсов.

2. **Модуль pGPU**\
   Используя официальный плагин устройства NVIDIA, он обеспечивает полную физическую изоляцию GPU с учетом планирования NUMA. Разработан для высокопроизводительных вычислительных задач (HPC), требующих выделенного доступа к GPU.

3. **Модуль MPS**\
   Реализует службу многопроцессного сервиса NVIDIA, позволяя одновременно выполнять контексты GPU с ограничениями ресурсов. Оптимизирует приложения с чувствительностью к задержкам через объединение ядер CUDA.

## Преимущества продукта

### Модуль vGPU

- **Динамическое разделение**: Разделение GPU для поддержки многопоточного использования одного физического GPU.
- **Обеспечение качества обслуживания (QoS)**: Гарантированные вычислительные единицы (vcuda-core) и квоты по памяти (vcuda-memory).

### Модуль pGPU

- **Изоляция на аппаратном уровне**: Прямой вывод PCIe с защитой IOMMU.
- **Оптимизация NUMA**: Минимизация передачи данных между сокетами за счет автоматической привязки к узлам NUMA.

### Модуль MPS

- **Выполнение с низкой задержкой**: Снижение задержки на 30-50% за счет объединения контекстов CUDA.
- **Ограничения ресурсов**: Ограничение вычислений GPU (0-100%) и использования памяти для каждого процесса.
- **Отсутствие изменений в коде**: Работает с неподвержденными приложениями CUDA.

## Сценарии применения

### Случаи использования vGPU

- **Мультиарендные AI-платформы**: Совместное использование GPU A100/H100 между командами с гарантированными SLA.
- **VDI-среды**: Обеспечение виртуальных рабочих столов с ускорением GPU для CAD/3D визуализации.
- **Пакетная инференция**: Параллелизация обслуживания моделей с дробной выделением GPU.

### Случаи использования pGPU

- **HPC-кластеры**: Запуск MPI-заданий с исключительным доступом к GPU для моделирования погоды.
- **Обучение ML**: Полное использование GPU для обучения крупных языковых моделей.
- **Медицинская визуализация**: Обработка данных MRI высокого разрешения без конкуренции за ресурсы.

### Случаи использования MPS

- **Инференция в реальном времени**: Анализ видео с низкой задержкой с использованием параллельных потоков CUDA.
- **Оркестрация микросервисов**: Совмещение нескольких микросервисов GPU на совместно используемом оборудовании.
- **Высококонкурентное обслуживание**: Увеличение QPS в 3 раза для систем рекомендаций.

## Технические ограничения

### Необходимые привилегии

#### Требования к доступу к аппаратным устройствам

Разрешения на доступ к файловым устройствам
Устройства NVIDIA GPU требуют прямого доступа к защищенным системным ресурсам:

```bash
# Владение и разрешения файлов устройств
$ ls -l /dev/nvidia*
crw-rw-rw- 1 root root 195,   0 1 авг 10:00 /dev/nvidia0
crw-rw-rw- 1 root root 195, 255 1 авг 10:00 /dev/nvidiactl
crw-rw-rw- 1 root root 195, 254 1 авг 10:00 /dev/nvidia-uvm
```

- **Требование**: Доступ root для чтения/записи файлов устройства.
- **Последствия**: Контейнеры без прав root получают ошибки отказа в разрешении.

#### Операции на уровне ядра

Необходимые взаимодействия с драйверами NVIDIA

| Операция          | Требуемая привилегия   | Цель                        |
| ------------------ | --------------------- | -------------------------- |
| Загрузка модуля    | CAP\_SYS\_MODULE      | Загрузка модулей ядра NVIDIA |
| Управление памятью  | CAP\_IPC\_LOCK        | Распределение памяти GPU    |
| Обработка прерываний | CAP\_SYS\_RAWIO       | Обработка прерываний GPU   |

#### Требования архитектуры плагина устройств K8s

1. **Создание сокета**: Запись в `/var/lib/kubelet/device-plugins`.
2. **Мониторинг состояния**: Доступ к `nvidia-smi` и журналам ядра.
3. **Распределение ресурсов**: Модификация cgroup устройств.

### Ограничения vGPU

- Поддержка только CUDA версии ниже 12.4.
- Нет поддержки MIG при включенном vGPU.

### Ограничения pGPU

- Нет возможности совместного использования GPU (маппинг 1:1 pod-to-GPU).
- Требуется Kubernetes 1.25+ с включенным SR-IOV.
- Ограничено GPU, подключенным через PCIe/NVSwitch.

### Ограничения MPS

- Возможная цепная реакция ошибок в объединенных контекстах.
- Требуется CUDA 11.4+ для ограничений памяти.
- Нет поддержки GPU с разделением MIG.

---
