---
weight: 16
---

# 创建标准类型集群

标准类型集群是使用 Ceph 存储最典型的方式，能够将数据副本分布在不同主机的硬盘上，单台主机故障时，其他主机上的数据副本仍然能继续提供服务。

## 前提条件

* 存储集群中至少需有 3 个节点。

* 每个节点上至少准备 1 块空白硬盘或 1 块未被格式化的硬盘分区。

* 可用硬盘容量建议大于 50G。

* 若您使用接入的 Kubernetes 集群，且运行时组件为 Containerd，请确认集群所有节点上 `/etc/systemd/system/containerd.service` 文件的  `LimitNOFILE` 参数值均配置为 `1048576`，以确保分布式存储部署成功。配置方式请参考 [修改 Containerd 配置信息]()。

  **说明**：当您从 v3.10.2 之前的版本升级至当前版本时，若需要在自建的运行时组件为 Containerd 的 Kubernetes 集群上部署 Ceph 分布式存储，也需将集群所有节点上 `/etc/systemd/system/containerd.service` 文件的 `LimitNOFILE` 参数值配置为 `1048576`。

## 注意事项

**创建存储服务** 和 **接入存储服务** 仅支持选择其中一种方式。

## 操作步骤

<Steps>
### 部署 Operator

1. 进入 **平台管理**。

1. 在左侧导航栏中，单击 **存储管理** > **分布式存储**。

3. 单击 **立即配置**。

3.  在 **部署 Operator** 向导页中，单击右下角 **部署 Operator** 按钮。  
      
    *   待页面自动进入下一步时，说明 Operator 部署成功。        
        
    *   如果部署失败，请参考界面提示 **清理已部署信息并重试**，重新部署 Operator；若您想返回分布式存储选择页，请单击 **应用商店**，首先卸载已经部署 **rook-operator** 内的资源实例，再卸载 **rook-operator**。

### 创建集群


1.  在 **创建集群** 向导页中，配置相关参数，单击右下角 **创建集群** 按钮。  

    |参数| 说明                                                         |
    | ---------------- | ------------------------------------------------------------ |
    |**集群类型**|选择 **标准**。|
    | **设备类类型** |设备类是对硬盘的分组，您可以根据存储需求自定义设备类，将不同存储内容分配至不同性能的存储硬盘中。<ul><li>**默认设备类**：平台将自动按照集群节点中的硬盘类型进行分类。例如创建 `hdd`、`ssd`、`nvme`名称的设备类。</li><li>**自定义设备类**：为节点中的指定硬盘组合自定义设备类名称，支持添加多个设备类。同一硬盘只能属于一个设备类。</li></ul> |
    | **设备类 - 名称** | 设备类的名称，选择 **自定义设备类** 时，设备类不能使用以下名称：`hdd`、`ssd`、`nvme`。 |
    | **设备类 - 存储设备** | 在节点中选择 **空白硬盘** 或 **未被格式化的硬盘分区**。<ul><li>打开所有空设备开关时：将节点下的所有空设备添加至该设备类；</li><li>关闭所有空设备开关时：手动输入节点下的空设备名称，例如 `sda`。</li></ul> |
    | **快照** | 开启后，支持创建 PVC 快照并使用快照配置新的 PVC，以快速备份恢复业务数据。<br/>若创建存储时未开启快照，您仍可以在存储集群详情页面的 **操作** 中按需开启。<br/>**注意**：使用前请确保已为当前集群 [部署卷快照插件](/storage/pv_snapshot/functions/snapshot_con.mdx)。|  
    | **监控告警** | 开启后，将提供开箱即用的监控指标采集和告警提醒能力，详见 [监控与告警](../functions/monitor.mdx) 。 <br/>**注意**：若此时不开启，您只能另行寻找存储监控与告警的替代方案。例如，在运维中心手动配置监控面板和告警策略。|

4. 单击 **高级配置**，进行组件高级配置。

    |参数| 说明                                                         |
    | ---------------- | ------------------------------------------------------------ |
    | **网络配置** | <ul><li>**主机网络**：存储集群将使用主机网络，您在优化参数列填写相关网络优化参数，例如配置 `public` 和 `cluster` 网段。若为空，则使用默认主机网段。<br></br>**说明**：使用主机网络时存在主机端口明文传输的安全风险，可以联系平台支持获取传输加密方案。</li><li>**容器网络**：存储集群将使用容器网络，您可在网络管理中创建子网并将子网分配至 `rook-ceph` 命名空间。若为空，则使用默认子网。<br></br>**说明**：<br></br>容器网络不支持 IPv6。<br></br>使用容器网络时存储仅能供本集群使用。<br></br>ceph csi pod 异常或者重启会导致业务中断。</li></ul> |
    | **优化参数** | 支持以 Ceph 配置文件格式填写参数，系统将根据填写的内容覆盖默认参数。<br/>**注意**：初次填写或修改初始化参数后，请单击初始化参数，初始化成功后才可创建集群。|
    | **组件定点部署** | 您可将组件定点部署至指定节点中，节点数需不少于三个，以保证最小可用性，定点部署配置生效的组件包括 MON、MGR、MDS、RGW。|

     * 待页面自动进入下一步时，说明 Ceph 集群部署成功。
     
     * 如果创建失败，可单击清理 **已创建信息或重试** 自动清理资源并重新创建集群，或根据文档 [分布式存储服务资源清理](../how_to/clean_ceph.mdx) 手动清理资源。

### 创建存储池

1.  在 **创建存储池** 向导页中，配置相关参数，单击右下角 **创建存储池** 按钮。  

    |参数| 说明                                                         |
    | ------------ | ------------------------------------------------------------ |
    | **存储类型** | <ul><li>文件存储：提供安全可靠、可扩展的共享文件存储服务。适用于文件共享、数据备份等场景。</li><li> 块存储：提供高 IOPS，低延迟的存储服务。适用于数据库、虚拟化等场景。</li><li> 对象存储：提供标准 S3 接口存储服务，适用于大数据、备份归档、网盘等场景。 </li></ul>|
    | **副本数量** | 副本数量越大，冗余度越高，数据越安全，但存储的利用率也将降低。通常设置为 3 可满足大部分需求。|
    | **设备类** | 为同一类型的设备或同一业务逻辑的硬盘统一划分类型，在创建的存储池中选择上一步已添加的设备类。<ul><li>选择设备类时，数据将存储至已选择的设备类中。</li><li>未选择设备类时，数据将随机存储至存储池中的所有设备中。</li></ul>|
    
    若为对象存储，您还需配置以下参数：
    
    |参数| 说明                                                         |
    | ------------ | ------------------------------------------------------------ |
    | **区域** | 填写存储池所在的区域。 |
    | **网关类型** | 默认为 S3 且无法修改。 |
    | **内部端口** | 填写集群内部访问的端口。 |
    | **外部访问** | 开启/关闭外部访问将会创建/销毁 Nodeport 类型的 Service。 |
    | **实例数量** | 对象存储的资源实例数量。|

    *   待页面自动进入下一步时，说明存储池部署成功。        
        
    *   如果部署失败，请参考界面提示检查核心组件，随后单击 **清理已创建信息并重试** 重新创建存储池。


2. 单击 **创建存储池**。在 **详细信息** 页签中，可查看创建的存储池等信息。

</Steps>

## 相关操作

### 创建延伸类型集群

具体请参考 [创建延伸类型集群](./create_service_extend.mdx)。

### 清理分布式存储

具体请参考 [清理分布式存储](../how_to/clean_ceph.mdx)。
