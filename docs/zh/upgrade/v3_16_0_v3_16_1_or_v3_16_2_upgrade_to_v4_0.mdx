---
weight: 30
sourceSHA: 572eac86c5777a40b31532b66e2b47dc45b108eab2aa4681f4d1598e1389bd0e
---

# 升级 <Term name="productShort" /> v3.16.0、v3.16.1 或 v3.16.2 到 v4.0

## 重要升级注意事项

- **在将 k8s 从低于 1.31 的版本升级到 1.31 时，节点上的所有 pods 将会被重启一次。在此过程中，pods 不会被重建或重新调度，但会发生服务中断。**
- 从 v4.0 开始，为了减少升级灾难恢复环境的复杂性，**在升级灾难恢复环境时，首先升级备用集群**，以避免在升级过程中发生灾难恢复切换。
- 本升级文档适用于将 x86 和 ARM 架构的 v3.16.0、v3.16.1 或 v3.16.2 升级到 v4.0.0 版本。
- 升级前，请确保所有集群已升级到 v3.16.0、v3.16.1 或 v3.16.2 版本。k8s 版本必须至少升级到 1.28。
- 升级前，请检查 global 集群的组件列表。如果有状态异常的组件，除非计划通过升级解决问题，否则不要进行升级。
- 如果平台上部署了服务网格且服务网格版本低于 Istio 1.20，则必须在进行平台升级之前先升级服务网格。
- ClickHouse 日志中心插件在新版本中已达到 Beta 级别，但不支持平滑升级。如果平台上安装了 Clickhouse 日志插件，请在升级前卸载该插件，并在工作负载集群完成升级后安装 ACP 日志存储和 Clickhouse。
- CostManager 插件和 Kubecost 插件在版本 4.0 中已停用。如果平台上部署了 Costmanager 插件和 Kubecost 插件，请在升级前卸载它们。
- 如果镜像仓库使用 MinIO 作为存储后端，并且 MinIO 使用 global 集群的三个主节点的 /cpaas/minio 目录，请确保这三个节点的 /cpaas/minio 目录中剩余空间至少为 120GB。如果不足，请扩展容量。
- 安装包将复制到 global 集群的第一个主节点上，解压后将占用最多 120GB 的空间。因此，当安装包和解压目录在同一磁盘上时，磁盘可用空间需要超过 250GB。
- 上传镜像大约需要两个小时，因此请提前规划升级时间。
- 如果在升级过程中出现问题，请先查看升级常见问题文档。

## 灾难恢复环境 (DR) 升级流程

### 数据对比

<Directive type="warning" title="警告">
  在升级之前，请务必执行以下两个步骤。
</Directive>

1. 升级前，请按照维护文档执行灾难恢复环境的数据对比脚本，以确保主备 global 集群之间没有不一致。
2. 在主备 global 集群上执行以下命令： `kubectl get machines.platform.tkestack.io`，确保返回的主机中没有非 Running 状态的节点。

### 卸载灾难恢复数据同步程序

1. 访问主集群的任一主节点，执行以下命令停止 etcd 同步 pod。

```shell
helm3 del etcd-sync -n default 2> /dev/null
helm3 del etcd-sync -n cpaas-system 2> /dev/null

kubectl delete configmaps,secret -n kube-system etcd-master-mirror-cert etcd-slave-mirror-cert etcd-sync-env etcd-sync-ignore-text &> /dev/null

kubectl delete deploy -n kube-system etcd-mirror-etcd-mirror &> /dev/null

kubectl get pod -n kube-system | grep etcd-mirror # 确保没有剩余的 etcd-mirror pod
```

### 升级备用集群

1. 切换集群访问地址的域名指向 **备集群** ，等待 5 分钟后检查解析结果是否更新。
2. 使用备用集群的 VIP 访问 **备用集群** 页面
   1. 如果无法通过 IP 访问平台页面，请登录到 **备用集群** 的 master1 节点，并修改 prdb 添加其他平台访问地址：
   ```yaml
   spec:
     alternativeURLs:
     - https://192.168.162.10 # 用实际的备用集群 VIP 替换 IP
   ```
3. 请参考 [上传平台镜像](#upload-platform-images) 段落，将平台镜像上传到 **备用集群** 。
4. 请参考 [升级 global 集群](#upgrade-the-global-cluster) 段落，升级 **备用集群的** global 。
5. 等待 **备用集群的** global 升级完成。

### 升级主集群

1. 切换集群访问地址的域名指向主集群，等待 5 分钟后检查解析结果是否更新。
2. 请参考 [上传平台镜像](#upload-platform-images) 段落，将平台镜像上传到主集群。
3. 请参考 [升级 global 集群](#upgrade-the-global-cluster) 段落，升级主集群的 global。
4. 等待主集群的 global 升级完成。

### 启动同步程序

1. 启动数据同步的 pod。
   1. 检查主集群和备用集群 VIP 的 2379 端口，确认它们已转发到各自的主节点。
   2. 通过 **备用集群** 的 Kubernetes VIP 访问 **备用集群** 平台页面，点击 global 集群插件部署页面，然后点击部署 etcd 同步插件。按照屏幕上的提示输入参数，其中：
      1. 数据检查间隔用于生成监控数据，默认值一般可以选择。
      2. 打印详细日志的开关默认不需开启，主要用于调试问题。
2. 等待插件部署成功。
3. 登录 **备用集群的** global master1 节点，检查 etcd 同步 pod 是否正常工作。

```shell
kubectl get po -n cpaas-system -l app=etcd-sync # 确保 pod 状态为 1/1 Running

kubectl logs -n cpaas-system $(kubectl get po -n cpaas-system -l app=etcd-sync --no-headers | awk '{print $1}' | head -1) | grep -i "Start Sync update"

# 等待输出返回 "Start Sync update"

# 重新创建一个 pod 实例，确保所有依赖于 ownerefrence 的 k8s 资源都能同步。
kubectl delete po -n cpaas-system $(kubectl get po -n cpaas-system -l app=etcd-sync --no-headers | awk '{print $1}' | head -1)
```

4. 登录备用集群的 global master1 节点检查数据同步是否完成。

```shell
curl "$(kubectl get svc -n cpaas-system etcd-sync-monitor -ojsonpath='{.spec.clusterIP}')/check"

# 输出含义：
"LOCAL ETCD missed keys:" # 表示主集群有这些键，但备用集群没有。这通常是因为 pod 启动时，由于资源顺序，键在被同步后被 k8s 垃圾回收。在这种情况下，重新启动其中一个 etcd-sync pod 即可：

"LOCAL ETCD surplus keys:" # 表示备用集群存在但主集群没有的键。这些键在备用集群中被视为多余。在从备用集群删除这些键之前，请与运维人员确认。
```

### [升级业务集群](#upgrade-business-clusters-1)

## 备份

<Directive type="warning" title="警告">
  步骤 1 必须在所有集群的每个主节点上执行，包括 global 集群（主集群和备用集群），以及所有业务集群。
</Directive>

1. 在所有集群的每个主节点上执行以下命令以备份 etcd。

```shell
tmp_dir="/cpaas/backup_$(date +%Y%m%d%H)"
mkdir -p "${tmp_dir}" && cp -r /etc/kubernetes/ "${tmp_dir}" && cp -r /var/lib/etcd/ "${tmp_dir}"
```

2. 如果 IaaS 条件允许，建议对所有机器进行快照备份。
3. 如果 IaaS 条件允许，建议对 Harbor、Jenkins、GitLab 和 Nexus 等第三方工具使用的外部存储进行快照备份；否则，可能无法回滚。
4. 如果 IaaS 不能对外部存储进行快照备份，则：通过执行命令 `cp -a` 复制 Harbor、GitLab 和 SonarQube 等第三方工具的数据目录。

## 上传平台镜像

1. 将新版本的安装包拷贝到 global 集群的第一个 master 节点，解压。
2. cd 进入新版本安装包解压之后的目录
3. 为降低实际升级所需时间，请在正式升级前，执行 内部镜像仓库、外部镜像仓库 中适合实际场景的对应命令，以上传镜像。
4. **如果是容灾集群，需要先检查平台访问域名是否指向备集群，先往备 global 集群上传镜像。等待备 global 集群升级完毕，切换域名解析到主集群，再往主 global 集群上传镜像。**
5. 如果使用内部镜像仓库部署平台，执行如下命令上传镜像。
```shell
bash upgrade.sh --only-sync-image=true
```
6. 如果使用外部镜像仓库部署平台，执行如下命令上传镜像。
```shell
bash upgrade.sh --registry <external registry address> --username <username> --password <password> --only-sync-image=true

# e.g.
# bash upgrade.sh --registry "example.com" --username admin --password password --only-sync-image=true
```

## 触发升级

<Directive type="info" title="信息">
  对于灾难恢复集群，您必须首先根据“上传镜像”步骤命令完成镜像上传，然后才能触发升级。
</Directive>

1. 在 global 集群的主节点上（离线安装程序已解压缩的地方）执行以下命令

```shell
bash upgrade.sh
```

2. 等待升级脚本完成。

## 升级 global 集群

1. 访问 global 页面，点击平台管理 > 集群管理 > 选择 global 集群，选择功能组件，然后点击升级。
2. 升级界面将显示组件升级信息。
3. 阅读信息并确认。

<Directive type="note" title="注意">
  名为 "Kubernetes" 的组件可以不升级，但强烈建议在升级 <Term name="productShort" /> 时触发 "Kubernetes" 组件的升级。\
  因为 <Term name="productShort" /> 本身的升级也可能导致工作负载中断，避免工作负载中断的正确方法不是不升级 "Kubernetes" 组件。
</Directive>

4. 点击升级。
5. 等待升级完成。

## 升级业务集群

### 注意事项

1. 您必须在升级任何业务集群之前，首先完成 [升级 global 集群](#upgrade-the-global-cluster)。
2. 本升级文档适用于将业务集群从版本 v3.16.0、v3.16.1 或 v3.16.2 升级到 v4.0.0，支持 x86\_64 和 arm64 架构。
3. 升级前，请检查业务集群的组件列表。如果有状态异常的组件，则除非计划通过升级解决此问题，否则请勿继续升级。
4. 如果集群使用了服务网格功能，请首先参考 [升级服务网格](#upgrade-service-mesh) 部分，检查当前业务集群的 Kubernetes 版本是否符合 Istio 升级要求。如果不符合，您需要将 Kubernetes 升级到满足 Istio 升级要求的版本。
5. 服务网格的 Sidecar 升级将对 Pods 进行滚动更新，可能会导致短暂的业务中断，特别是对于长连接服务。
6. 随着集群的升级，现有的 PostgreSQL 实例将会自动重启以进行升级更新，从而在更新过程中导致短暂的服务中断。
7. 随着集群的升级，设置为自动更新策略的 MySQL-PXC、MySQL-MGR、Redis、Kafka 和 RabbitMQ 实例将自动重启以进行升级更新，导致更新过程中的短暂服务中断。
8. 如果在升级过程中出现问题，请优先查阅升级常见问题文档。
9. 同时支持最多 20 个业务集群的升级。

### 升级业务集群的功能组件

1. 访问平台管理页面，点击“集群”，选择要升级的业务集群，点击“功能组件”，然后点击“升级”。
2. 升级界面将显示组件升级信息。
3. 阅读信息并确认。

<Directive type="note" title="注意">
  名为 "Kubernetes" 的组件可以不升级，但强烈建议在升级 <Term name="productShort" /> 时触发 "Kubernetes" 组件的升级。\
  因为 <Term name="productShort" /> 本身的升级也可能导致工作负载中断，避免工作负载中断的正确方法不是不升级 "Kubernetes" 组件。
</Directive>

4. 点击升级按钮。
5. 如果当前环境已修改配置设置，点击升级时会弹出确认窗口。请联系运维团队核实这些配置是否会影响升级。
6. 等待升级完成。

### 升级 DevOps 工具链实例

<Directive type="note" title="注意">
  （如果未部署任何 DevOps 工具链，则跳过此步骤）
</Directive>

1. 转到平台管理 > 工具链管理 > 工具链集成，然后点击工具链名称。
2. 在集成详情页面，点击实例名称以进入实例详情页面。
3. 如果工具名称的右侧出现升级图标，点击操作 > 升级，并根据客户需求进行工具升级。点击升级信息图标，以实时查看实例更新状态。
4. 如果没有升级图标，意味着该工具没有可用的升级版本。请检查其他工具。

### 升级服务网格

<Directive type="note" title="注意">
  （如果未部署服务网格，则跳过此步骤）
</Directive>

有关升级流程，请参考产品用户手册：平台管理 > 服务网格 > 升级服务网格。

#### Istio 升级的 Kubernetes 版本要求

<table>
  <thead>
    <tr>
      <th>升级前 Istio 版本</th>
      <th>升级后 Istio 版本</th>
      <th>Istio 主版本升级所需的 Kubernetes 版本</th>
      <th>相应的 ACP 升级场景</th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>Istio 1.20</td>
      <td>Istio 1.22</td>
      <td>Kubernetes 1.27,1.28,1.29</td>

      <td>
        ACP 3.18 升级到 4.0<br />
        ACP 3.16 升级到 4.0
      </td>
    </tr>
  </tbody>
</table>

## 升级常见问题

当前没有已知问题。
