---
weight: 20
sourceSHA: 7a9c1d8bbaec834cc30df84cbc9367a37f4f2c4ecdb1ac66ae0d85570b3ce785
---

# 日志模块架构

![](../assets/log.png)

## 整体架构说明

日志系统由以下核心功能模块组成：
1. 日志采集
   - 基于开源组件 filebeat 提供
   - 日志采集：支持采集标准输出日志、文件日志、Kubernetes 事件和审计

2. 日志存储
   - 基于开源组件 Clickhouse 和 ElasticSearch 提供了两种不同的日志存储解决方案。
   - 日志存储：支持长期存储日志文件。
   - 日志存储时间管理：支持在项目级别管理日志存储时长。

3. 日志可视化
   - 提供便捷可靠的日志查询、日志导出和日志分析能力。

## 日志采集

### 组件安装方式

nevermore 以 daemonset 形式安装在各个集群的 cpaas-system 命名空间下，该组件由4个容器组成：

| 名称                  | 功能                                                    |
| --------------------- | --------------------------------------------------------- |
| audit                 | 采集审计数据                                           |
| event                 | 采集事件数据                                           |
| log                   | 采集日志数据（包括标准输出和文件日志）                  |
| node-problem-detector | 采集节点上的异常信息                                   |

### 数据采集流程

nevermore 采集审计、事件和日志信息后，会将数据发送到日志存储集群，经过 Razor 鉴权后，最终存放到 ElasticSearch 或 ClickHouse 中。

## 日志消费及存储

### Razor

Razor 负责鉴权及接收和转发日志消息。

- 在 Razor 接收到来自各个工作负载集群的 nevermore 发送的请求后，首先使用请求中的 Token 进行认证。如果认证失败，则拒绝请求。
- 如果安装的日志存储组件是 ElasticSearch，它会将相应的日志写入 Kafka 集群。
- 如果安装的日志存储组件是 Clickhouse，它会将相应的日志传递给 Vector，最终写入 Clickhouse。

### Lanaya

Lanaya 负责在 ElasticSearch 日志存储链路中消费和转发日志数据。

- Lanaya 订阅 Kafka 中的主题，在收到订阅消息后，会先对消息进行解压缩。
- 解压缩后，会对消息进行预处理，添加必要字段、转换字段及拆分数据。
- 最终，它会根据消息的时间和类型将消息存储到 ElasticSearch 相应的索引中。

### Vector

Vector 负责在 Clickhouse 日志存储链路中处理和转发日志数据，最终将日志存储到 Clickhouse 对应的表中。

## 日志可视化

1. 用户可以从产品 UI 界面查询审计、事件和日志的查询 URL 进行展示：
   - 日志查询 /platform/logging.alauda.io/v1
   - 事件查询 /platform/events.alauda.io/v1
   - 审计查询 /platform/audits.alauda.io/v1

2. 请求会由高级 API 组件 Courier 处理，Courier 会从日志存储集群 ElasticSearch 或 Clickhouse 查询日志数据并返回到页面。
