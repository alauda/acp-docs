---
weight: 40
---

# Kafka 存储空间优化

Kafka 用户应该密切监控 Kafka 实例的存储空间使用率，过高的使用率可能导致 Kafka 的正常运行受阻。一般建议保持 Kafka 集群的存储空间使用率在 50-70% 的范围内。如果使用率持续上升，应采取相应措施以避免出现空间不足的问题对系统造成影响。

## 日志文件过多

在 Kafka 中，消息数据被存储在日志文件中。如果不对日志文件的数量和大小进行控制，就会导致大量的存储空间被占用。因此，需要定期清理旧的数据和日志，并且合理配置日志文件的大小等参数。

通过自动清理 Kafka 中的数据，我们可以有效控制磁盘上的数据大小，删除不必要的数据，并且减少对 Kafka 集群的维护成本。这样的措施不仅能优化存储空间的利用，还能保证 Kafka 的高效运行。

|参数|说明|
|---|---|
|**log.cleanup.policy**|**delete**（默认）：根据数据保留的时间以及 log 的 max size，对数据进行 cleanup。**compact**：在一个分片中，对任意一个 key，它所对应的 value 都是最新的。|

## 消息过期数据未清理

在 Kafka 中，消息的有效期可以通过 `retention.ms` 参数进行配置。如果过期的消息没有及时清理，将会占用存储空间。为了解决这个问题，Kafka 使用基于 segment 的定期清理机制。正在使用的 segment 不会被清理，只有当 `log.retention.hours` 或 `log.retention.bytes` 中的任何一个达到设置的要求时，才会执行删除操作。

|参数|说明|
|---|---|
|**log.retention.hours**|日志文件保留时长，默认 7 天。清理超过指定时间的消息的消息。|
|**log.retention.bytes**|日志文件保留大小。超过指定大小后，删除旧消息，默认为 -1，不删除。|
|**log.segment.bytes**|日志文件最大值，默认值为 1073741824，即 1GB。当前日志分段文件的大小超过了该参数配置的值时，会触发日志文件的切分。|
|**log.roll.hours**|当前日志分段中消息的最大时间戳与当前系统的时间戳的差值允许的最大范围，单位：小时。|

## 使用消息压缩

在 Kafka 中，消息压缩是一种常用的优化策略，可以通过压缩消息来减少存储空间和网络传输的带宽占用。Kafka 提供了多种压缩算法可供选择，如 zstd、LZ4、snappy 和 GZIP 等。在使用消息压缩时，需要考虑以下几个方面：

1. 压缩算法的选择
    
    压缩算法的选择是基于压缩比和性能之间的权衡。不同压缩算法在这些方面具有不同的特点。例如，zstd 算法通常具有较高的压缩比和较快的速度，但对 CPU 资源要求较高。相比之下，snappy 和 LZ4 算法提供更快的速度和较低的延迟，但压缩比相对较低。因此，在选择压缩算法时，需要综合考虑实际业务需求和可用的硬件资源。

2. 压缩前后的消息延迟

    使用压缩算法进行消息压缩和解压缩操作会消耗一定的CPU资源，并且可能引入一定的消息分发延迟。因此，在决定是否启用消息压缩之前，需要进行综合考虑集群的带宽、存储和 CPU 资源情况。如果带宽和存储资源有限，而 CPU 资源相对充足，则可以考虑启用压缩以减少存储和网络开销。然而，在 CPU 资源接近饱和的情况下，需要谨慎评估是否开启压缩，以避免对集群性能产生负面影响。
    
3. 压缩参数的配置

    在使用 Kafka 消息压缩时，需要在生产者和消费者的配置文件中设置相关参数。比如，`compression.type` 参数用于指定要使用的压缩算法。
    
    吞吐量：LZ4 > Snappy > zstd > GZIP。
    
    压缩比：zstd > LZ4 > GZIP > Snappy。
    
    |参数|说明|
    |---|---|
    |**compression.type**|可选值 `uncompressed`、`zstd`、`lz4`、`snappy`、`gzip`、`producer`。|

## 存储空间监控

Kafka 提供了一些度量指标来监控存储空间的使用情况。我们需要定期查看度量指标，发现存储空间使用率持续增长的情况下采取相应的措施。通过监控和存储空间的优化措施，可以更好地管理 Kafka 集群的存储空间，避免由于存储空间问题而导致的故障，从而确保 Kafka 的稳定运行。

|指标|说明|
|---|---|
|**log.log_end_offset**|当前日志中最后一条消息的 offset。通过比较不同 topic 和分区的 `log_end_offset`，可以了解每个分区的存储空间使用情况。|
|**log.segment.bytes**|每个日志段的大小。|
|**log.segment.ms**|每个日志段的时间段。可以根据时间段判断是否需要清理旧的数据和日志。|
|**log.retention.bytes**|存储在 Kafka 中的消息的总大小阈值。当消息的总大小超过该阈值时，Kafka 会自动删除旧的消息。|
|**log.retention.hours**|消息在 Kafka 中的保留时间。超过该时间限制的消息将被自动删除。|