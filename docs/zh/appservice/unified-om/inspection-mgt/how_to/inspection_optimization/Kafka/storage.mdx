---
weight: 40
sourceSHA: d4aecf6202a2adc7ec3f476ddb8814f602f82f380fe4efcd5d46fb2c67fd2ba9
---

# Kafka 存储空间优化

Kafka 用户应密切监控其 Kafka 实例的存储空间利用情况，因为过度使用可能会阻碍 Kafka 的正常操作。通常建议将 Kafka 集群的存储空间利用率保持在 50-70% 的范围内。如果使用率持续上升，则应采取适当措施以避免空间不足对系统产生影响。

## 过多的日志文件

在 Kafka 中，消息数据存储在日志文件中。如果不控制日志文件的数量和大小，可能会占用大量存储空间。因此，有必要定期清理旧数据和日志，并适当配置如日志文件大小等参数。

通过自动清理 Kafka 中的数据，我们可以有效地控制磁盘上的数据大小，去除不必要的数据，并降低 Kafka 集群的维护成本。这些措施不仅可以优化存储空间的利用率，还可以确保 Kafka 的高效运行。

| 参数                     | 说明                                                                                                                                                       |
|--------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|
| **log.cleanup.policy**   | **delete**（默认）：根据保留时间和日志的最大大小清理数据。 **compact**：对于一个分区中的任何键，其对应的值将是最新的。                                     |

## 未清理的过期消息

在 Kafka 中，可以使用 `retention.ms` 参数配置消息的有效保留时间。如果过期消息未能及时清理，它们将占用存储空间。为了解决此问题，Kafka 使用基于段的定期清理机制。当前正在使用的段将不会被清理；只有当 `log.retention.hours` 或 `log.retention.bytes` 达到配置要求时，才会执行删除操作。

| 参数                     | 说明                                                                                                                                                                                |
|--------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **log.retention.hours**  | 日志文件的保留时长，默认为 7 天。清理超过此指定时间的消息。                                                                                                                         |
| **log.retention.bytes**  | 日志文件的保留大小。一旦超过指定大小，将删除旧消息，默认为 -1（不删除）。                                                                                                        |
| **log.segment.bytes**    | 日志文件的最大大小，默认值为 1073741824（即 1GB）。当当前日志段文件的大小超过此配置值时，将触发日志文件的轮换。                                                                 |
| **log.roll.hours**       | 当前日志段中最新消息的时间戳与当前系统时间戳之间的最大允许范围，单位为小时。                                                                                                     |

## 消息压缩

在 Kafka 中，消息压缩是一种常用的优化策略，可以通过压缩消息来减少存储空间和带宽的使用。Kafka 提供了多种压缩算法供选择，如 zstd、LZ4、snappy 和 GZIP。在使用消息压缩时，应考虑以下几个方面：

1. 压缩算法的选择

   压缩算法的选择是基于压缩比和性能之间的权衡。不同的压缩算法在这些方面具有不同的特性。例如，zstd 算法通常能实现更高的压缩比和更快的速度，但需要更多的 CPU 资源。相比之下，snappy 和 LZ4 算法提供更快的速度和较低的延迟，但压缩比相对较低。因此，选择压缩算法时，必须考虑实际的业务需求和可用的硬件资源。

2. 压缩前后的消息延迟

   使用压缩算法对消息进行压缩和解压缩将消耗一定的 CPU 资源，并可能引入一些消息调度延迟。因此，在决定是否启用消息压缩之前，有必要全面评估集群的带宽、存储和 CPU 资源情况。如果带宽和存储资源有限，而 CPU 资源相对充足，可以考虑启用压缩以减少存储和网络开销。然而，在 CPU 资源接近饱和的情况下，则需要谨慎评估是否启用压缩，以避免对集群性能产生负面影响。

3. 压缩参数的配置

   在使用 Kafka 消息压缩时，需要在生产者和消费者的配置文件中设置相关参数。例如，`compression.type` 参数用于指定要使用的压缩算法。

   吞吐量： LZ4 > Snappy > zstd > GZIP。

   压缩比： zstd > LZ4 > GZIP > Snappy。

   | 参数                     | 说明                                                                        |
   |--------------------------|-----------------------------------------------------------------------------|
   | **compression.type**     | 可选值：`uncompressed`、`zstd`、`lz4`、`snappy`、`gzip`、`producer`。  |

## 存储空间监控

Kafka 提供了多种指标来监控存储空间的利用情况。我们需要定期检查这些指标，并在发现存储空间利用率持续上升时采取适当措施。通过对存储空间的监控和优化措施，我们可以更好地管理 Kafka 集群的存储空间，防止因存储空间问题导致的故障，从而确保 Kafka 的稳定运行。

| 指标                      | 说明                                                                                                                                                                             |
|--------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **log.log\_end\_offset** | 当前日志中最后一条消息的偏移量。通过比较不同主题和分区的 `log_end_offset`，可以了解每个分区的存储空间利用情况。                                                               |
| **log.segment.bytes**    | 每个日志段的大小。                                                                                                                                                              |
| **log.segment.ms**       | 每个日志段的时间长度。这可以用来判断是否需要清理旧数据和日志。                                                                                                                  |
| **log.retention.bytes**  | Kafka 中存储的消息的总大小阈值。当总大小超过此阈值时，Kafka 将自动删除旧消息。                                                                                                    |
| **log.retention.hours**  | Kafka 中消息的保留时长。超过此时间限制的消息将被自动删除。                                                                                                                      |
