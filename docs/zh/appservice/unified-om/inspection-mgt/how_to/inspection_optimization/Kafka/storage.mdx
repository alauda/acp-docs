---
sourceSHA: d4aecf6202a2adc7ec3f476ddb8814f602f82f380fe4efcd5d46fb2c67fd2ba9
---

# Kafka 存储空间优化

Kafka 用户应密切监控其 Kafka 实例的存储空间使用情况，过度使用可能会妨碍 Kafka 的正常运行。一般建议将 Kafka 集群的存储空间使用率维持在 50-70% 的范围内。如果使用率持续上升，则应采取适当措施，避免因空间不足对系统产生影响。

## 过多的日志文件

在 Kafka 中，消息数据存储在日志文件中。如果不控制日志文件的数量和大小，会占用大量存储空间。因此，有必要定期清理旧数据和日志，并适当配置日志文件大小等参数。

通过自动清理 Kafka 中的数据，我们可以有效控制磁盘上的数据大小，移除不必要的数据，降低 Kafka 集群的维护成本。这些措施不仅可以优化存储空间的利用，还能确保 Kafka 的高效运行。

| 参数                    | 描述                                                                                                                                                         |
| ---------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **log.cleanup.policy** | **delete**（默认）：根据保留时间和日志的最大大小清理数据。**compact**：对于分区中的任何键，其对应的值为最新值。                                                                                        |

## 未清理的过期消息

在 Kafka 中，可以通过 `retention.ms` 参数配置消息的有效持续时间。如果过期消息未及时清理，将占用存储空间。为了解决这个问题，Kafka 使用基于段的定期清理机制。当前使用的段不会被清理；只有当 `log.retention.hours` 或 `log.retention.bytes` 达到配置要求时，才会执行删除操作。

| 参数                     | 描述                                                                                                                                                                          |
| ----------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **log.retention.hours** | 日志文件的保留时长，默认 7 天。清理超过该指定时间的消息。                                                                                                                   |
| **log.retention.bytes** | 日志文件的保留大小。一旦超过指定大小，将删除旧消息，默认值为 -1（不删除）。                                                                                                 |
| **log.segment.bytes**   | 日志文件的最大大小，默认值为 1073741824（即 1GB）。当当前日志段文件的大小超过此配置值时，将触发日志文件的滚动。                                                            |
| **log.roll.hours**      | 当前日志段中最新消息的时间戳与当前系统时间戳之间的最大允许间隔，以小时为单位。                                                                                              |

## 消息压缩

在 Kafka 中，消息压缩是一种常用的优化策略，可以通过压缩消息来降低存储空间和带宽使用。Kafka 提供了几种压缩算法可供选择，例如 zstd、LZ4、snappy 和 GZIP。在使用消息压缩时，应考虑以下方面：

1. 压缩算法的选择

   压缩算法的选择基于压缩比与性能之间的权衡。不同的压缩算法在这些方面具有不同的特性。例如，zstd 算法通常实现更高的压缩比和更快的速度，但需要更多的 CPU 资源。相比之下，snappy 和 LZ4 算法提供更快的速度和较低的延迟，但压缩比相对较低。因此，在选择压缩算法时，务必考虑实际业务需求与可用的硬件资源。

2. 压缩前后的消息延迟

   使用压缩算法对消息进行压缩和解压会消耗一定的 CPU 资源，并可能引入一些消息派送延迟。因此，在决定是否启用消息压缩之前，需要全面评估集群的带宽、存储和 CPU 资源情况。如果带宽和存储资源有限，而 CPU 资源相对丰富，可以考虑启用压缩以降低存储和网络开销。然而，在 CPU 资源接近饱和的情况下，则需要仔细评估是否启用压缩，以避免对集群性能产生负面影响。

3. 压缩参数的配置

   在使用 Kafka 消息压缩时，需在生产者和消费者的配置文件中设置相关参数。例如，`compression.type` 参数用于指定要使用的压缩算法。

   吞吐量：LZ4 > Snappy > zstd > GZIP。

   压缩比：zstd > LZ4 > GZIP > Snappy。

   | 参数                  | 描述                                                                   |
   | -------------------- | --------------------------------------------------------------------- |
   | **compression.type** | 可选值：`uncompressed`、`zstd`、`lz4`、`snappy`、`gzip`、`producer`。 |

## 存储空间监控

Kafka 提供了多个指标来监控存储空间的利用率。我们需要定期检查这些指标，并在发现存储空间利用率持续增加时采取适当措施。通过对存储空间的监控和优化，我们可以更好地管理 Kafka 集群的存储空间，并防止因存储空间问题导致的故障，从而确保 Kafka 的稳定运行。

| 指标                     | 描述                                                                                                                                                                                 |
| ---------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **log.log\_end\_offset** | 当前日志中最后一条消息的偏移量。通过比较不同主题和分区的 `log_end_offset`，可以了解每个分区的存储空间利用情况。                                                                      |
| **log.segment.bytes**    | 每个日志段的大小。                                                                                                                                                                   |
| **log.segment.ms**       | 每个日志段的时间持续时间。这可以用来判断是否需要清理旧数据和日志。                                                                                                                  |
| **log.retention.bytes**  | Kafka 中存储的消息的总大小阈值。当总大小超过此阈值时，Kafka 将自动删除旧消息。                                                                                                      |
| **log.retention.hours**  | Kafka 中消息的保留时限。超过此时间限制的消息将自动删除。                                                                                                                            |
