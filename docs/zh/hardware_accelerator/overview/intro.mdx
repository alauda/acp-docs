---
weight: 10
sourceSHA: 1520c5380271e3635c7b9e6233edd2c9e61e72c3f13a8eed8ed794c565edbf3d
---

# 介绍

## 硬件加速器介绍

Kubernetes 硬件加速器套件是一种企业级解决方案，旨在优化云原生环境中 GPU 资源的分配、隔离和共享。该套件基于 Kubernetes 设备插件和 NVIDIA 原生技术，提供三个核心模块：

1. **vGPU 模块**\
   基于开源 GPU-Manager，此模块通过将物理 GPU 切分为可共享的虚拟单元（具备内存/计算配额）来实现细粒度的 GPU 虚拟化。非常适合需要动态资源分配的多租户环境。

2. **pGPU 模块**\
   利用 NVIDIA 官方设备插件，提供具有 NUMA 感知调度的完整物理 GPU 隔离。专为需要专用 GPU 访问的高性能计算（HPC）工作负载设计。

3. **MPS 模块**\
   实现 NVIDIA 的多进程服务，允许在资源限制下并发执行 GPU 上下文。通过 CUDA 内核融合优化对延迟敏感的应用程序。

## 产品优势

### vGPU 模块

- **动态切片**：将 GPU 切分以支持多进程使用一个物理 GPU
- **QoS 强制执行**：保证计算单元（vcuda-core）和内存配额（vcuda-memory）

### pGPU 模块

- **硬件级隔离**：直接 PCIe 直通，加上 IOMMU 保护
- **NUMA 优化**：通过自动 NUMA 节点绑定最小化跨套接字数据传输

### MPS 模块

- **低延迟执行**：通过 CUDA 上下文融合实现 30-50% 的延迟减少
- **资源限制**：限制每个进程的 GPU 计算（0-100%）和内存使用
- **零代码更改**：适用于未修改的 CUDA 应用程序

## 应用场景

### vGPU 用例

- **多租户 AI 平台**：在团队之间共享 A100/H100 GPU，并提供保底服务水平协议（SLA）
- **虚拟桌面基础环境（VDI）**：为 CAD/3D 渲染提供 GPU 加速虚拟桌面
- **批量推理**：通过分配部分 GPU 实现模型服务并行化

### pGPU 用例

- **HPC 集群**：为天气模拟运行独占 GPU 访问的 MPI 作业
- **机器学习训练**：充分利用 GPU 进行大语言模型的训练
- **医学影像**：处理高分辨率 MRI 数据，而不发生资源争用

### MPS 用例

- **实时推理**：使用并发的 CUDA 流进行低延迟视频分析
- **微服务编排**：在共享硬件上共同承载多个 GPU 微服务
- **高并发服务**：为推荐系统提升 3 倍的每秒查询率（QPS）

## 技术限制

### 需要特权

#### 硬件设备访问要求

设备文件权限  
NVIDIA GPU 设备需要直接访问受保护的系统资源：

```bash
# 设备文件所有权和权限
$ ls -l /dev/nvidia*
crw-rw-rw- 1 root root 195,   0 Aug 1 10:00 /dev/nvidia0
crw-rw-rw- 1 root root 195, 255 Aug 1 10:00 /dev/nvidiactl
crw-rw-rw- 1 root root 195, 254 Aug 1 10:00 /dev/nvidia-uvm
```

- **要求**：根用户访问以读/写设备文件
- **后果**：非根容器会出现权限不足错误

#### 内核级操作

NVIDIA 驱动程序的基本交互

| 操作                  | 特权要求               | 目的                          |
| --------------------- | ---------------------- | ----------------------------- |
| 模块加载              | CAP\_SYS\_MODULE      | 加载 NVIDIA 内核模块          |
| 内存管理              | CAP\_IPC\_LOCK        | GPU 内存分配                  |
| 中断处理              | CAP\_SYS\_RAWIO       | 处理 GPU 中断                 |

#### K8s 设备插件架构要求

1. **创建套接字**：写入 `/var/lib/kubelet/device-plugins`
2. **健康监测**：访问 `nvidia-smi` 和内核日志
3. **资源分配**：修改设备控制组

### vGPU 限制

- 仅支持 CUDA 版本低于 12.4
- vGPU 启用时不支持 MIG

### pGPU 限制

- 不具备 GPU 共享能力（1:1 Pod 到 GPU 映射）
- 需要 Kubernetes 1.25 及以上版本，并开启 SR-IOV
- 限制在 PCIe/NVSwitch 连接的 GPU 上

### MPS 限制

- 在融合上下文之间可能出现故障传播
- 需要 CUDA 11.4 及以上版本以实现内存限制
- 不支持 MIG 切片的 GPU

---
